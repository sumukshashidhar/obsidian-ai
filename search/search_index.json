{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Obsidian-AI","text":"<p>A command-line AI assistant that chats with your personal knowledge base using OpenAI's GPT models. Search, read, and semantically explore your notes with natural language queries.</p>"},{"location":"#overview","title":"Overview","text":"<p>Obsidian-AI transforms your note collection into an intelligent knowledge base. Using advanced search capabilities and AI-powered analysis, it helps you:</p> <ul> <li>Discover connections between your notes and ideas</li> <li>Search semantically using natural language queries  </li> <li>Explore relationships through wikilink analysis</li> <li>Chat interactively with your knowledge base</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#smart-search","title":"\ud83d\udd0d Smart Search","text":"<ul> <li>Keyword search across filenames and content</li> <li>Semantic search using local TF-IDF embeddings</li> <li>Exact phrase matching for precise queries</li> <li>Wikilink analysis to find connected notes</li> </ul>"},{"location":"#safe-secure","title":"\ud83d\udee1\ufe0f Safe &amp; Secure","text":"<ul> <li>Read-only operations - never modifies your files</li> <li>Directory sandboxing restricts access to your brain directory</li> <li>No secrets in code - API keys only via environment variables</li> <li>Size limits prevent processing of overly large files</li> </ul>"},{"location":"#interactive-experience","title":"\ud83d\udcac Interactive Experience","text":"<ul> <li>Single queries for quick answers</li> <li>REPL mode for extended conversations</li> <li>Rich terminal output with syntax highlighting</li> <li>Tool integration with search, read, and semantic analysis</li> </ul>"},{"location":"#high-performance","title":"\ud83d\ude80 High Performance","text":"<ul> <li>Local caching of embeddings and search indices</li> <li>Efficient file processing with configurable limits</li> <li>Concurrent operations for faster responses</li> <li>Smart ignore patterns to skip irrelevant files</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li> <p>Install Obsidian-AI:    <pre><code>pip install obsidian-ai\n</code></pre></p> </li> <li> <p>Configure your environment:    <pre><code>export OPENAI_API_KEY=\"your-api-key\"\nexport OBSIDIAN_AI_BRAIN_DIR=\"$HOME/brain\"\n</code></pre></p> </li> <li> <p>Start chatting with your notes:    <pre><code>obsidian-ai chat \"What notes do I have about machine learning?\"\n</code></pre></p> </li> </ol>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#research-writing","title":"Research &amp; Writing","text":"<ul> <li>Find related notes when working on papers or articles</li> <li>Discover connections between different research topics</li> <li>Get summaries of your thoughts on specific subjects</li> </ul>"},{"location":"#personal-knowledge-management","title":"Personal Knowledge Management","text":"<ul> <li>Explore relationships between people, projects, and ideas</li> <li>Find forgotten notes related to current interests</li> <li>Maintain context across long-term projects</li> </ul>"},{"location":"#learning-study","title":"Learning &amp; Study","text":"<ul> <li>Review notes on specific topics</li> <li>Find examples and explanations in your knowledge base</li> <li>Connect new learning to existing knowledge</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>Obsidian-AI follows bacterial coding principles - small, modular, self-contained components that work together:</p> <pre><code>src/obsidian_ai/\n\u251c\u2500\u2500 core/           # Search engines and analysis tools\n\u251c\u2500\u2500 infrastructure/ # Configuration and file system\n\u251c\u2500\u2500 services/       # External API integrations\n\u251c\u2500\u2500 interfaces/     # CLI and chat interfaces\n\u2514\u2500\u2500 prompts/        # AI prompt templates\n</code></pre> <p>Each module is designed to be: - Small - focused on a single responsibility - Modular - easily swappable components - Self-contained - minimal dependencies - Copy-pasteable - reusable in other projects</p>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation Guide - Detailed setup instructions</li> <li>Configuration - Customize for your workflow</li> <li>Usage Examples - Common patterns and workflows</li> <li>API Reference - Detailed code documentation</li> </ul> <p>Ready to explore your knowledge base? Let's get started!</p>"},{"location":"api/core/","title":"Core API Reference","text":"<p>The core module contains the main search and analysis functionality.</p>"},{"location":"api/core/#search-engine","title":"Search Engine","text":""},{"location":"api/core/#obsidian_ai.core.search_engine","title":"search_engine","text":""},{"location":"api/core/#obsidian_ai.core.search_engine.ExactPhraseSearch","title":"ExactPhraseSearch","text":"<p>Search for exact phrases with case insensitive matching.</p> Source code in <code>src/obsidian_ai/core/search_engine.py</code> <pre><code>class ExactPhraseSearch:\n    \"\"\"Search for exact phrases with case insensitive matching.\"\"\"\n\n    def search(self, query: str, max_results: int) -&gt; list[SearchResult]:\n        if not query.strip():\n            return []\n\n        pattern = re.compile(re.escape(query.strip()), re.IGNORECASE)\n        results: list[SearchResult] = []\n\n        for path in iter_text_files(config.brain_dir, config.ignore_patterns):\n            if len(results) &gt;= max_results:\n                break\n\n            try:\n                text = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n                lines = text.splitlines()\n\n                for line_num, line in enumerate(lines, 1):\n                    if pattern.search(line):\n                        # Get context around the match\n                        context_lines = []\n                        for i in range(max(0, line_num - 2), min(len(lines), line_num + 2)):\n                            context_lines.append(lines[i].strip())\n                        context = \" | \".join(context_lines)\n\n                        results.append(\n                            SearchResult(\n                                path=str(path),\n                                line=line_num,\n                                text=context[:300],\n                                brain_dir=config.brain_dir,\n                                score=2.0,  # Higher score for exact matches\n                            )\n                        )\n                        break\n            except Exception:\n                continue\n\n        return results\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.search_engine.FilenameSearch","title":"FilenameSearch","text":"<p>Search filenames for partial matches.</p> Source code in <code>src/obsidian_ai/core/search_engine.py</code> <pre><code>class FilenameSearch:\n    \"\"\"Search filenames for partial matches.\"\"\"\n\n    def search(self, query: str, max_results: int) -&gt; list[SearchResult]:\n        query_lower = query.lower()\n        keywords = query_lower.split()\n        results: list[SearchResult] = []\n\n        for path in iter_text_files(config.brain_dir, config.ignore_patterns):\n            filename_lower = path.name.lower()\n\n            if any(keyword in filename_lower for keyword in keywords):\n                try:\n                    text = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n                    first_lines = \"\\n\".join(text.splitlines()[:3])\n                    results.append(\n                        SearchResult(\n                            path=str(path),\n                            line=1,\n                            text=f\"\ud83d\udcc1 {path.name}: {first_lines[:150]}\",\n                            brain_dir=config.brain_dir,\n                            score=1.5,  # Medium score for filename matches\n                        )\n                    )\n                except Exception:\n                    results.append(SearchResult(path=str(path), line=1, text=f\"\ud83d\udcc1 {path.name}\", brain_dir=config.brain_dir, score=1.0))\n\n            if len(results) &gt;= max_results:\n                break\n\n        return results\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.search_engine.KeywordSearch","title":"KeywordSearch","text":"<p>Search for individual keywords with scoring.</p> Source code in <code>src/obsidian_ai/core/search_engine.py</code> <pre><code>class KeywordSearch:\n    \"\"\"Search for individual keywords with scoring.\"\"\"\n\n    def search(self, query: str, max_results: int) -&gt; list[SearchResult]:\n        keywords = [k.strip().lower() for k in query.split() if len(k.strip()) &gt; 2]\n        if not keywords:\n            return []\n\n        results: list[tuple[SearchResult, int]] = []  # (result, score)\n\n        for path in iter_text_files(config.brain_dir, config.ignore_patterns):\n            try:\n                text = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n                lines = text.splitlines()\n\n                for line_num, line in enumerate(lines, 1):\n                    line_lower = line.lower()\n                    score = sum(1 for keyword in keywords if keyword in line_lower)\n\n                    if score &gt; 0:\n                        results.append(\n                            (SearchResult(path=str(path), line=line_num, text=line.strip()[:200], brain_dir=config.brain_dir, score=score), score)\n                        )\n            except Exception:\n                continue\n\n        # Sort by score and return top results\n        results.sort(key=lambda x: x[1], reverse=True)\n        return [result for result, _ in results[:max_results]]\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.search_engine.SearchResult","title":"SearchResult  <code>dataclass</code>","text":"<p>A single search result.</p> Source code in <code>src/obsidian_ai/core/search_engine.py</code> <pre><code>@dataclass(frozen=True)\nclass SearchResult:\n    \"\"\"A single search result.\"\"\"\n\n    path: str\n    line: int\n    text: str\n    brain_dir: Path\n    score: float = 1.0\n\n    @property\n    def relative_path(self) -&gt; str:\n        return str(Path(self.path).relative_to(self.brain_dir))\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.search_engine.SearchStrategy","title":"SearchStrategy","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for search strategies.</p> Source code in <code>src/obsidian_ai/core/search_engine.py</code> <pre><code>class SearchStrategy(Protocol):\n    \"\"\"Protocol for search strategies.\"\"\"\n\n    def search(self, query: str, max_results: int) -&gt; list[SearchResult]:\n        \"\"\"Execute the search strategy.\"\"\"\n        ...\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.search_engine.SearchStrategy.search","title":"search","text":"<pre><code>search(query: str, max_results: int) -&gt; list[SearchResult]\n</code></pre> <p>Execute the search strategy.</p> Source code in <code>src/obsidian_ai/core/search_engine.py</code> <pre><code>def search(self, query: str, max_results: int) -&gt; list[SearchResult]:\n    \"\"\"Execute the search strategy.\"\"\"\n    ...\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.search_engine.UnifiedSearchEngine","title":"UnifiedSearchEngine","text":"<p>Unified search engine that combines multiple search strategies.</p> Source code in <code>src/obsidian_ai/core/search_engine.py</code> <pre><code>class UnifiedSearchEngine:\n    \"\"\"Unified search engine that combines multiple search strategies.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.strategies: list[SearchStrategy] = [ExactPhraseSearch(), KeywordSearch(), FilenameSearch()]\n\n    def search(self, query: str, max_results: int = 10) -&gt; list[SearchResult]:\n        \"\"\"Execute multi-strategy search and combine results.\"\"\"\n        all_results: list[SearchResult] = []\n        seen_lines: set[str] = set()\n\n        # Execute each strategy\n        for strategy in self.strategies:\n            strategy_results = strategy.search(query, max_results // 2)\n\n            for result in strategy_results:\n                key = f\"{result.path}:{result.line}\"\n                if key not in seen_lines:\n                    all_results.append(result)\n                    seen_lines.add(key)\n\n        # Sort by score and return top results\n        all_results.sort(key=lambda x: x.score, reverse=True)\n        return all_results[:max_results]\n\n    def search_json(self, query: str, max_results: int = 10) -&gt; str:\n        \"\"\"Return search results as JSON string.\"\"\"\n        results = self.search(query, max_results)\n\n        return json.dumps(\n            {\n                \"query\": query,\n                \"results\": [{\"path\": result.relative_path, \"line\": result.line, \"text\": result.text, \"score\": result.score} for result in results],\n                \"count\": len(results),\n                \"search_strategies\": \"exact_phrase, keywords, filename_matching\",\n            }\n        )\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.search_engine.UnifiedSearchEngine.search","title":"search","text":"<pre><code>search(\n    query: str, max_results: int = 10\n) -&gt; list[SearchResult]\n</code></pre> <p>Execute multi-strategy search and combine results.</p> Source code in <code>src/obsidian_ai/core/search_engine.py</code> <pre><code>def search(self, query: str, max_results: int = 10) -&gt; list[SearchResult]:\n    \"\"\"Execute multi-strategy search and combine results.\"\"\"\n    all_results: list[SearchResult] = []\n    seen_lines: set[str] = set()\n\n    # Execute each strategy\n    for strategy in self.strategies:\n        strategy_results = strategy.search(query, max_results // 2)\n\n        for result in strategy_results:\n            key = f\"{result.path}:{result.line}\"\n            if key not in seen_lines:\n                all_results.append(result)\n                seen_lines.add(key)\n\n    # Sort by score and return top results\n    all_results.sort(key=lambda x: x.score, reverse=True)\n    return all_results[:max_results]\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.search_engine.UnifiedSearchEngine.search_json","title":"search_json","text":"<pre><code>search_json(query: str, max_results: int = 10) -&gt; str\n</code></pre> <p>Return search results as JSON string.</p> Source code in <code>src/obsidian_ai/core/search_engine.py</code> <pre><code>def search_json(self, query: str, max_results: int = 10) -&gt; str:\n    \"\"\"Return search results as JSON string.\"\"\"\n    results = self.search(query, max_results)\n\n    return json.dumps(\n        {\n            \"query\": query,\n            \"results\": [{\"path\": result.relative_path, \"line\": result.line, \"text\": result.text, \"score\": result.score} for result in results],\n            \"count\": len(results),\n            \"search_strategies\": \"exact_phrase, keywords, filename_matching\",\n        }\n    )\n</code></pre>"},{"location":"api/core/#wikilink-parser","title":"Wikilink Parser","text":""},{"location":"api/core/#obsidian_ai.core.wikilink_parser","title":"wikilink_parser","text":""},{"location":"api/core/#obsidian_ai.core.wikilink_parser.WikiLink","title":"WikiLink","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Represents a parsed wikilink.</p> Source code in <code>src/obsidian_ai/core/wikilink_parser.py</code> <pre><code>class WikiLink(NamedTuple):\n    \"\"\"Represents a parsed wikilink.\"\"\"\n\n    target: str\n    display_text: str | None = None\n\n    def __str__(self) -&gt; str:\n        if self.display_text:\n            return f\"[[{self.target}|{self.display_text}]]\"\n        return f\"[[{self.target}]]\"\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.wikilink_parser.WikiLinkParser","title":"WikiLinkParser","text":"<p>Parser for extracting and processing wikilinks.</p> Source code in <code>src/obsidian_ai/core/wikilink_parser.py</code> <pre><code>class WikiLinkParser:\n    \"\"\"Parser for extracting and processing wikilinks.\"\"\"\n\n    @staticmethod\n    def extract_wikilinks(text: str) -&gt; list[WikiLink]:\n        \"\"\"Extract all wikilinks from text.\"\"\"\n        # Pattern to match [[content]] - handles nested brackets\n        pattern = r\"\\[\\[([^\\[\\]]*(?:\\[[^\\[\\]]*\\][^\\[\\]]*)*)\\]\\]\"\n        matches = re.findall(pattern, text)\n\n        wikilinks = []\n        for match in matches:\n            if \"|\" in match:\n                target, display = match.split(\"|\", 1)\n                wikilinks.append(WikiLink(target.strip(), display.strip()))\n            else:\n                wikilinks.append(WikiLink(match.strip()))\n\n        return wikilinks\n\n    @staticmethod\n    def extract_link_targets(text: str) -&gt; list[str]:\n        \"\"\"Extract just the target names from wikilinks.\"\"\"\n        wikilinks = WikiLinkParser.extract_wikilinks(text)\n        return [link.target for link in wikilinks]\n\n    @staticmethod\n    def extract_unique_targets(text: str) -&gt; list[str]:\n        \"\"\"Extract unique target names from wikilinks.\"\"\"\n        targets = WikiLinkParser.extract_link_targets(text)\n        return list(dict.fromkeys(targets))  # Preserve order while removing duplicates\n\n    @staticmethod\n    def replace_wikilinks(text: str, replacement_func: Callable[[WikiLink, str], str]) -&gt; str:\n        \"\"\"Replace wikilinks in text using a replacement function.\"\"\"\n\n        def replace_match(match: re.Match[str]) -&gt; str:\n            full_link = match.group(0)\n            link_content = match.group(1)\n\n            if \"|\" in link_content:\n                target, display = link_content.split(\"|\", 1)\n                wikilink = WikiLink(target.strip(), display.strip())\n            else:\n                wikilink = WikiLink(link_content.strip())\n\n            return replacement_func(wikilink, full_link)\n\n        pattern = r\"\\[\\[([^\\[\\]]*(?:\\[[^\\[\\]]*\\][^\\[\\]]*)*)\\]\\]\"\n        return re.sub(pattern, replace_match, text)\n\n    @staticmethod\n    def validate_wikilink(text: str) -&gt; bool:\n        \"\"\"Check if text contains valid wikilink syntax.\"\"\"\n        pattern = r\"\\[\\[([^\\[\\]]*(?:\\[[^\\[\\]]*\\][^\\[\\]]*)*)\\]\\]\"\n        return bool(re.search(pattern, text))\n\n    @staticmethod\n    def count_wikilinks(text: str) -&gt; int:\n        \"\"\"Count the number of wikilinks in text.\"\"\"\n        return len(WikiLinkParser.extract_wikilinks(text))\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.wikilink_parser.WikiLinkParser.count_wikilinks","title":"count_wikilinks  <code>staticmethod</code>","text":"<pre><code>count_wikilinks(text: str) -&gt; int\n</code></pre> <p>Count the number of wikilinks in text.</p> Source code in <code>src/obsidian_ai/core/wikilink_parser.py</code> <pre><code>@staticmethod\ndef count_wikilinks(text: str) -&gt; int:\n    \"\"\"Count the number of wikilinks in text.\"\"\"\n    return len(WikiLinkParser.extract_wikilinks(text))\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.wikilink_parser.WikiLinkParser.extract_link_targets","title":"extract_link_targets  <code>staticmethod</code>","text":"<pre><code>extract_link_targets(text: str) -&gt; list[str]\n</code></pre> <p>Extract just the target names from wikilinks.</p> Source code in <code>src/obsidian_ai/core/wikilink_parser.py</code> <pre><code>@staticmethod\ndef extract_link_targets(text: str) -&gt; list[str]:\n    \"\"\"Extract just the target names from wikilinks.\"\"\"\n    wikilinks = WikiLinkParser.extract_wikilinks(text)\n    return [link.target for link in wikilinks]\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.wikilink_parser.WikiLinkParser.extract_unique_targets","title":"extract_unique_targets  <code>staticmethod</code>","text":"<pre><code>extract_unique_targets(text: str) -&gt; list[str]\n</code></pre> <p>Extract unique target names from wikilinks.</p> Source code in <code>src/obsidian_ai/core/wikilink_parser.py</code> <pre><code>@staticmethod\ndef extract_unique_targets(text: str) -&gt; list[str]:\n    \"\"\"Extract unique target names from wikilinks.\"\"\"\n    targets = WikiLinkParser.extract_link_targets(text)\n    return list(dict.fromkeys(targets))  # Preserve order while removing duplicates\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.wikilink_parser.WikiLinkParser.extract_wikilinks","title":"extract_wikilinks  <code>staticmethod</code>","text":"<pre><code>extract_wikilinks(text: str) -&gt; list[WikiLink]\n</code></pre> <p>Extract all wikilinks from text.</p> Source code in <code>src/obsidian_ai/core/wikilink_parser.py</code> <pre><code>@staticmethod\ndef extract_wikilinks(text: str) -&gt; list[WikiLink]:\n    \"\"\"Extract all wikilinks from text.\"\"\"\n    # Pattern to match [[content]] - handles nested brackets\n    pattern = r\"\\[\\[([^\\[\\]]*(?:\\[[^\\[\\]]*\\][^\\[\\]]*)*)\\]\\]\"\n    matches = re.findall(pattern, text)\n\n    wikilinks = []\n    for match in matches:\n        if \"|\" in match:\n            target, display = match.split(\"|\", 1)\n            wikilinks.append(WikiLink(target.strip(), display.strip()))\n        else:\n            wikilinks.append(WikiLink(match.strip()))\n\n    return wikilinks\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.wikilink_parser.WikiLinkParser.replace_wikilinks","title":"replace_wikilinks  <code>staticmethod</code>","text":"<pre><code>replace_wikilinks(\n    text: str,\n    replacement_func: Callable[[WikiLink, str], str],\n) -&gt; str\n</code></pre> <p>Replace wikilinks in text using a replacement function.</p> Source code in <code>src/obsidian_ai/core/wikilink_parser.py</code> <pre><code>@staticmethod\ndef replace_wikilinks(text: str, replacement_func: Callable[[WikiLink, str], str]) -&gt; str:\n    \"\"\"Replace wikilinks in text using a replacement function.\"\"\"\n\n    def replace_match(match: re.Match[str]) -&gt; str:\n        full_link = match.group(0)\n        link_content = match.group(1)\n\n        if \"|\" in link_content:\n            target, display = link_content.split(\"|\", 1)\n            wikilink = WikiLink(target.strip(), display.strip())\n        else:\n            wikilink = WikiLink(link_content.strip())\n\n        return replacement_func(wikilink, full_link)\n\n    pattern = r\"\\[\\[([^\\[\\]]*(?:\\[[^\\[\\]]*\\][^\\[\\]]*)*)\\]\\]\"\n    return re.sub(pattern, replace_match, text)\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.wikilink_parser.WikiLinkParser.validate_wikilink","title":"validate_wikilink  <code>staticmethod</code>","text":"<pre><code>validate_wikilink(text: str) -&gt; bool\n</code></pre> <p>Check if text contains valid wikilink syntax.</p> Source code in <code>src/obsidian_ai/core/wikilink_parser.py</code> <pre><code>@staticmethod\ndef validate_wikilink(text: str) -&gt; bool:\n    \"\"\"Check if text contains valid wikilink syntax.\"\"\"\n    pattern = r\"\\[\\[([^\\[\\]]*(?:\\[[^\\[\\]]*\\][^\\[\\]]*)*)\\]\\]\"\n    return bool(re.search(pattern, text))\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.wikilink_parser.extract_key_terms","title":"extract_key_terms","text":"<pre><code>extract_key_terms(content: str) -&gt; list[str]\n</code></pre> <p>Extract key terms from content for finding related notes.</p> Source code in <code>src/obsidian_ai/core/wikilink_parser.py</code> <pre><code>def extract_key_terms(content: str) -&gt; list[str]:\n    \"\"\"Extract key terms from content for finding related notes.\"\"\"\n    # Extract wiki-style links first (before removing brackets)\n    wiki_targets = WikiLinkParser.extract_unique_targets(content)\n\n    # Remove markdown formatting\n    content = re.sub(r\"[#*`\\[\\]]+\", \"\", content)\n\n    # Extract potential names (capitalized words including multi-word phrases)\n    names = re.findall(r\"\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\b\", content)\n\n    # Extract important phrases (3+ character words)\n    words = re.findall(r\"\\b[a-zA-Z]{3,}\\b\", content)\n\n    # Combine and deduplicate\n    key_terms = list(dict.fromkeys(wiki_targets + names + words))\n\n    # Filter out common words\n    common_words = {\n        \"the\",\n        \"and\",\n        \"for\",\n        \"are\",\n        \"but\",\n        \"not\",\n        \"you\",\n        \"all\",\n        \"can\",\n        \"had\",\n        \"her\",\n        \"was\",\n        \"one\",\n        \"our\",\n        \"out\",\n        \"day\",\n        \"get\",\n        \"has\",\n        \"him\",\n        \"his\",\n        \"how\",\n        \"its\",\n        \"new\",\n        \"now\",\n        \"old\",\n        \"see\",\n        \"two\",\n        \"way\",\n        \"who\",\n        \"boy\",\n        \"did\",\n        \"may\",\n        \"say\",\n        \"she\",\n        \"use\",\n        \"your\",\n        \"each\",\n        \"make\",\n        \"most\",\n        \"over\",\n        \"said\",\n        \"some\",\n        \"time\",\n        \"very\",\n        \"what\",\n        \"with\",\n        \"have\",\n        \"from\",\n        \"they\",\n        \"know\",\n        \"want\",\n        \"been\",\n        \"good\",\n        \"much\",\n        \"more\",\n        \"will\",\n        \"well\",\n        \"where\",\n        \"come\",\n        \"could\",\n        \"should\",\n        \"would\",\n        \"there\",\n        \"their\",\n        \"which\",\n        \"about\",\n        \"after\",\n        \"first\",\n        \"never\",\n        \"these\",\n        \"think\",\n        \"other\",\n        \"many\",\n        \"than\",\n        \"then\",\n        \"them\",\n        \"before\",\n        \"here\",\n        \"this\",\n    }\n\n    filtered_terms = [term for term in key_terms if term.lower() not in common_words and len(term) &gt; 2]\n\n    # Sort by length (longer terms first, as they're likely more specific)\n    filtered_terms.sort(key=len, reverse=True)\n\n    return filtered_terms[:20]  # Return top 20 terms\n</code></pre>"},{"location":"api/core/#research-agent","title":"Research Agent","text":""},{"location":"api/core/#obsidian_ai.core.research_agent","title":"research_agent","text":""},{"location":"api/core/#obsidian_ai.core.research_agent.ResearchAgent","title":"ResearchAgent","text":"<p>Autonomous research agent that follows wikilinks and builds understanding iteratively.</p> Source code in <code>src/obsidian_ai/core/research_agent.py</code> <pre><code>class ResearchAgent:\n    \"\"\"Autonomous research agent that follows wikilinks and builds understanding iteratively.\"\"\"\n\n    def __init__(self):\n        self.prompts = ResearchPrompts()\n\n    def conduct_research(self, topic: str, max_iterations: int = 4) -&gt; dict[str, Any]:\n        \"\"\"\n        Conduct comprehensive research on a topic.\n\n        Returns:\n            Structured research results with steps, findings, and final report.\n        \"\"\"\n        try:\n            return self._execute_research(topic, max_iterations)\n        except Exception as e:\n            logger.error(f\"Research failed for topic '{topic}': {e}\")\n            return self._create_error_response(topic, str(e))\n\n    def _execute_research(self, topic: str, max_iterations: int) -&gt; dict[str, Any]:\n        \"\"\"Execute the research process.\"\"\"\n        research_steps: list[ResearchStep] = []\n        discovered_entities: set[str] = set()\n        explored_queries: set[str] = set()\n\n        current_focus = topic\n\n        for iteration in range(max_iterations):\n            logger.info(f\"Research iteration {iteration + 1} for topic: {topic}\")\n\n            try:\n                # Plan the next step\n                action_plan = self._plan_research_step(topic, current_focus, research_steps, discovered_entities)\n\n                # Avoid repeating queries\n                if action_plan[\"query\"] in explored_queries:\n                    action_plan[\"query\"] = self._generate_alternative_query(topic, explored_queries, research_steps)\n\n                explored_queries.add(action_plan[\"query\"])\n\n                # Execute the search\n                search_results, wikilinks_found = self._execute_search(action_plan)\n\n                # Update discovered entities\n                discovered_entities.update(wikilinks_found)\n\n                # Analyze relevant files\n                content_analysis = self._analyze_relevant_files(topic, search_results)\n\n                # Synthesize findings\n                synthesis = self._synthesize_findings(topic, action_plan, search_results, wikilinks_found, content_analysis, research_steps)\n\n                # Determine next actions\n                next_actions = self._determine_next_actions(topic, synthesis, discovered_entities, explored_queries)\n\n                # Create research step\n                step = ResearchStep(\n                    step_number=iteration + 1,\n                    reasoning=action_plan[\"reasoning\"],\n                    action=action_plan[\"action\"],\n                    query=action_plan[\"query\"],\n                    results=search_results,\n                    wikilinks_found=list(set(wikilinks_found)),\n                    synthesis=synthesis,\n                    next_actions=next_actions,\n                )\n\n                research_steps.append(step)\n\n                # Update focus for next iteration\n                if next_actions and iteration &lt; max_iterations - 1:\n                    current_focus = next_actions[0]\n\n                # Check if research is complete\n                if self._is_research_complete(synthesis, next_actions):\n                    logger.info(f\"Research completed early at iteration {iteration + 1}\")\n                    break\n\n            except Exception as e:\n                logger.error(f\"Error in research iteration {iteration + 1}: {e}\")\n                # Continue with next iteration rather than failing completely\n                continue\n\n        # Generate final report\n        final_report = self._generate_final_report(topic, research_steps, discovered_entities)\n\n        return {\n            \"topic\": topic,\n            \"total_iterations\": len(research_steps),\n            \"discovered_entities\": sorted(discovered_entities),\n            \"research_steps\": [\n                {\n                    \"step\": step.step_number,\n                    \"reasoning\": step.reasoning,\n                    \"action\": f\"{step.action}({step.query})\",\n                    \"results_found\": len(step.results),\n                    \"wikilinks_discovered\": step.wikilinks_found,\n                    \"synthesis\": step.synthesis,\n                    \"next_planned_actions\": step.next_actions,\n                }\n                for step in research_steps\n            ],\n            \"final_comprehensive_report\": final_report,\n            \"research_quality_metrics\": {\n                \"total_sources_examined\": sum(len(step.results) for step in research_steps),\n                \"unique_wikilinks_discovered\": len(discovered_entities),\n                \"research_depth_score\": len(research_steps) * len(discovered_entities),\n            },\n        }\n\n    def _plan_research_step(\n        self, topic: str, current_focus: str, previous_steps: list[ResearchStep], discovered_entities: set[str]\n    ) -&gt; dict[str, str]:\n        \"\"\"Plan the next research step using AI reasoning.\"\"\"\n        previous_context = \"\"\n        if previous_steps:\n            previous_context = \"\\n\\n**Previous Research Steps:**\\n\"\n            for step in previous_steps[-2:]:  # Last 2 steps for context\n                previous_context += f\"Step {step.step_number}: {step.action}('{step.query}') \u2192 {step.synthesis[:200]}...\\n\"\n\n        discovered_context = \"\"\n        if discovered_entities:\n            discovered_context = f\"\\n\\n**Entities Discovered So Far:** {', '.join(sorted(discovered_entities)[:10])}\"\n\n        try:\n            prompt = self.prompts.get_research_reasoning_prompt(\n                original_topic=topic, current_focus=current_focus, previous_context=previous_context, discovered_context=discovered_context\n            )\n\n            response = openai_client.simple_completion(prompt, max_tokens=400)\n            return self._parse_reasoning_response(response)\n\n        except OpenAIError as e:\n            logger.error(f\"Failed to plan research step: {e}\")\n            return {\"reasoning\": f\"Continue investigating {current_focus} to gather more information.\", \"action\": \"search\", \"query\": current_focus}\n\n    def _parse_reasoning_response(self, response: str) -&gt; dict[str, str]:\n        \"\"\"Parse the AI's reasoning response.\"\"\"\n        lines = response.split(\"\\n\")\n        result = {\"reasoning\": \"\", \"action\": \"search\", \"query\": \"\"}\n\n        for line in lines:\n            if line.startswith(\"REASONING:\"):\n                result[\"reasoning\"] = line.replace(\"REASONING:\", \"\").strip()\n            elif line.startswith(\"ACTION:\"):\n                result[\"action\"] = line.replace(\"ACTION:\", \"\").strip()\n            elif line.startswith(\"QUERY:\"):\n                result[\"query\"] = line.replace(\"QUERY:\", \"\").strip()\n\n        return result\n\n    def _execute_search(self, action_plan: dict[str, str]) -&gt; tuple[list[dict], list[str]]:\n        \"\"\"Execute the planned search and extract wikilinks.\"\"\"\n        search_results = []\n        wikilinks_found = []\n\n        try:\n            if action_plan[\"action\"] == \"search\":\n                results = search_engine.search(action_plan[\"query\"], max_results=12)\n                search_results = [\n                    {\"path\": result.relative_path, \"line\": result.line, \"text\": result.text, \"score\": result.score} for result in results\n                ]\n\n            elif action_plan[\"action\"] == \"semantic_search\":\n                semantic_data = embedding_service.semantic_search(action_plan[\"query\"], k=8)\n                search_results = semantic_data.get(\"results\", [])\n\n            # Extract wikilinks from all found content\n            for result in search_results:\n                content = result.get(\"text\", result.get(\"preview\", \"\"))\n                links = WikiLinkParser.extract_unique_targets(content)\n                wikilinks_found.extend(links)\n\n        except Exception as e:\n            logger.error(f\"Search execution failed: {e}\")\n\n        return search_results, wikilinks_found\n\n    def _analyze_relevant_files(self, topic: str, search_results: list[dict]) -&gt; str:\n        \"\"\"Analyze the most relevant files for deeper insights.\"\"\"\n        relevant_files = self._identify_relevant_files(search_results)\n        analysis_parts = []\n\n        for file_path in relevant_files[:3]:  # Limit to top 3 files\n            try:\n                content = read_file_safe(file_path, max_bytes=16384)\n                analysis = self._analyze_file_content(topic, file_path, content[:2000])\n                analysis_parts.append(f\"**Analysis of {file_path}:**\\n{analysis}\")\n\n            except Exception as e:\n                logger.warning(f\"Could not analyze file {file_path}: {e}\")\n                continue\n\n        return \"\\n\\n\".join(analysis_parts)\n\n    def _identify_relevant_files(self, search_results: list[dict]) -&gt; list[str]:\n        \"\"\"Identify files most relevant for deeper analysis.\"\"\"\n        file_scores = {}\n\n        for result in search_results:\n            path = result.get(\"path\", \"\")\n            if path:\n                text = result.get(\"text\", result.get(\"preview\", \"\"))\n                # Score based on content length and wikilink density\n                score = len(text) + text.lower().count(\"[[\") * 10\n                score += result.get(\"score\", 1.0) * 5  # Boost by search relevance\n\n                if path not in file_scores:\n                    file_scores[path] = 0\n                file_scores[path] += score\n\n        # Return files sorted by relevance score\n        sorted_files = sorted(file_scores.items(), key=lambda x: x[1], reverse=True)\n        return [path for path, _ in sorted_files]\n\n    def _analyze_file_content(self, topic: str, file_path: str, content: str) -&gt; str:\n        \"\"\"Analyze how relevant a file's content is to the research topic.\"\"\"\n        try:\n            prompt = self.prompts.get_content_analysis_prompt(topic=topic, file_path=file_path, content=content)\n\n            return openai_client.simple_completion(prompt, max_tokens=200)\n\n        except OpenAIError as e:\n            logger.error(f\"Content analysis failed for {file_path}: {e}\")\n            return f\"File {file_path} contains content related to {topic}.\"\n\n    def _synthesize_findings(\n        self, topic: str, action_plan: dict, search_results: list, wikilinks: list, content_analysis: str, previous_steps: list[ResearchStep]\n    ) -&gt; str:\n        \"\"\"Synthesize findings from this research step.\"\"\"\n        results_summary = f\"Found {len(search_results)} results from {action_plan['action']}('{action_plan['query']}')\"\n        if search_results:\n            results_summary += \":\\n\" + \"\\n\".join(\n                [f\"- {result.get('path', 'Unknown')}: {result.get('text', result.get('preview', ''))[:100]}...\" for result in search_results[:5]]\n            )\n\n        wikilinks_summary = f\"Discovered wikilinks: {', '.join(wikilinks[:10])}\" if wikilinks else \"No new wikilinks found.\"\n\n        previous_context = \"\"\n        if previous_steps:\n            previous_context = f\"\\n\\nBuilding on previous findings:\\n{previous_steps[-1].synthesis}\"\n\n        try:\n            prompt = self.prompts.get_step_synthesis_prompt(\n                topic=topic,\n                reasoning=action_plan[\"reasoning\"],\n                results_summary=results_summary,\n                wikilinks_summary=wikilinks_summary,\n                content_analysis=content_analysis,\n                previous_context=previous_context,\n            )\n\n            return openai_client.simple_completion(prompt, max_tokens=400)\n\n        except OpenAIError as e:\n            logger.error(f\"Synthesis failed: {e}\")\n            return f\"Step completed: {action_plan['action']} for '{action_plan['query']}' found {len(search_results)} results.\"\n\n    def _determine_next_actions(self, topic: str, synthesis: str, discovered_entities: set[str], explored_queries: set[str]) -&gt; list[str]:\n        \"\"\"Determine next research actions based on findings.\"\"\"\n        unexplored_entities = [entity for entity in discovered_entities if entity.lower() not in explored_queries and len(entity) &gt; 2]\n\n        try:\n            prompt = f\"\"\"Research Topic: \"{topic}\"\n\n**Current Synthesis:**\n{synthesis}\n\n**Unexplored Entities:** {\", \".join(unexplored_entities[:15])}\n**Already Explored:** {\", \".join(list(explored_queries)[-5:])}\n\nBased on the current synthesis, what are the 2-3 most important next research directions?\n\nConsider:\n- Which unexplored entities are most relevant to the topic?\n- What information gaps need to be filled?\n- Which connections should be explored deeper?\n\nReturn 2-3 specific research directions, each as a short phrase or entity name.\"\"\"\n\n            response = openai_client.simple_completion(prompt, max_tokens=200)\n            next_actions = [action.strip(\"- \").strip() for action in response.strip().split(\"\\n\") if action.strip()]\n            return next_actions[:3]\n\n        except OpenAIError:\n            return unexplored_entities[:2] if unexplored_entities else []\n\n    def _generate_alternative_query(self, topic: str, explored_queries: set[str], previous_steps: list[ResearchStep]) -&gt; str:\n        \"\"\"Generate alternative query when the planned one was already explored.\"\"\"\n        recent_findings = \"\"\n        if previous_steps:\n            recent_findings = previous_steps[-1].synthesis\n\n        try:\n            prompt = f\"\"\"Research Topic: \"{topic}\"\n\n**Already Explored:** {\", \".join(list(explored_queries))}\n**Recent Findings:** {recent_findings}\n\nGenerate a new, unexplored search query that would advance our understanding of this topic.\nFocus on a different angle or aspect that hasn't been covered yet.\n\nReturn only the search query:\"\"\"\n\n            return openai_client.simple_completion(prompt, max_tokens=50).strip()\n\n        except OpenAIError:\n            return f\"information about {topic}\"\n\n    def _is_research_complete(self, synthesis: str, next_actions: list[str]) -&gt; bool:\n        \"\"\"Determine if research has sufficient depth to conclude.\"\"\"\n        if len(synthesis) &lt; 100:\n            return False\n\n        if not next_actions:\n            return True\n\n        completion_indicators = [\"comprehensive understanding\", \"thorough investigation\", \"all major aspects covered\", \"no significant gaps\"]\n\n        return any(indicator in synthesis.lower() for indicator in completion_indicators)\n\n    def _generate_final_report(self, topic: str, research_steps: list[ResearchStep], discovered_entities: set[str]) -&gt; str:\n        \"\"\"Generate comprehensive final research report.\"\"\"\n        all_syntheses = \"\\n\\n\".join([f\"**Step {step.step_number}:** {step.synthesis}\" for step in research_steps])\n\n        all_wikilinks = []\n        for step in research_steps:\n            all_wikilinks.extend(step.wikilinks_found)\n        unique_wikilinks = list(set(all_wikilinks))\n\n        try:\n            prompt = self.prompts.get_final_report_prompt(\n                topic=topic,\n                all_syntheses=all_syntheses,\n                discovered_entities=\", \".join(sorted(discovered_entities)),\n                unique_wikilinks=\", \".join(unique_wikilinks[:20]),\n            )\n\n            return openai_client.simple_completion(prompt, max_tokens=1000)\n\n        except OpenAIError as e:\n            logger.error(f\"Final report generation failed: {e}\")\n            return f\"Research completed on '{topic}' with {len(research_steps)} iterations, discovering {len(discovered_entities)} related entities.\"\n\n    def _create_error_response(self, topic: str, error_msg: str) -&gt; dict[str, Any]:\n        \"\"\"Create an error response when research fails.\"\"\"\n        return {\n            \"topic\": topic,\n            \"total_iterations\": 0,\n            \"discovered_entities\": [],\n            \"research_steps\": [],\n            \"final_comprehensive_report\": f\"Research failed: {error_msg}\",\n            \"research_quality_metrics\": {\"total_sources_examined\": 0, \"unique_wikilinks_discovered\": 0, \"research_depth_score\": 0},\n            \"error\": error_msg,\n        }\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.research_agent.ResearchAgent.conduct_research","title":"conduct_research","text":"<pre><code>conduct_research(\n    topic: str, max_iterations: int = 4\n) -&gt; dict[str, Any]\n</code></pre> <p>Conduct comprehensive research on a topic.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Structured research results with steps, findings, and final report.</p> Source code in <code>src/obsidian_ai/core/research_agent.py</code> <pre><code>def conduct_research(self, topic: str, max_iterations: int = 4) -&gt; dict[str, Any]:\n    \"\"\"\n    Conduct comprehensive research on a topic.\n\n    Returns:\n        Structured research results with steps, findings, and final report.\n    \"\"\"\n    try:\n        return self._execute_research(topic, max_iterations)\n    except Exception as e:\n        logger.error(f\"Research failed for topic '{topic}': {e}\")\n        return self._create_error_response(topic, str(e))\n</code></pre>"},{"location":"api/core/#obsidian_ai.core.research_agent.ResearchStep","title":"ResearchStep  <code>dataclass</code>","text":"<p>Represents a single step in the research process.</p> Source code in <code>src/obsidian_ai/core/research_agent.py</code> <pre><code>@dataclass\nclass ResearchStep:\n    \"\"\"Represents a single step in the research process.\"\"\"\n\n    step_number: int\n    reasoning: str\n    action: str\n    query: str\n    results: list[dict[str, Any]]\n    wikilinks_found: list[str]\n    synthesis: str\n    next_actions: list[str]\n</code></pre>"},{"location":"api/infrastructure/","title":"Infrastructure API Reference","text":"<p>Infrastructure components for configuration and file system operations.</p>"},{"location":"api/infrastructure/#configuration","title":"Configuration","text":""},{"location":"api/infrastructure/#obsidian_ai.infrastructure.config","title":"config","text":""},{"location":"api/infrastructure/#file-system","title":"File System","text":""},{"location":"api/infrastructure/#obsidian_ai.infrastructure.file_system","title":"file_system","text":""},{"location":"api/infrastructure/#obsidian_ai.infrastructure.file_system.iter_text_files","title":"iter_text_files","text":"<pre><code>iter_text_files(\n    brain_dir: Path,\n    ignore_patterns: list[str] | None = None,\n) -&gt; Iterator[Path]\n</code></pre> <p>Iterate over text files in brain directory, respecting ignore patterns.</p> Source code in <code>src/obsidian_ai/infrastructure/file_system.py</code> <pre><code>def iter_text_files(brain_dir: Path, ignore_patterns: list[str] | None = None) -&gt; Iterator[Path]:\n    \"\"\"Iterate over text files in brain directory, respecting ignore patterns.\"\"\"\n    ignore_patterns = ignore_patterns or []\n\n    for path in brain_dir.rglob(\"*\"):\n        if not path.is_file():\n            continue\n\n        # Check if file should be ignored\n        if any(pattern in str(path) for pattern in ignore_patterns):\n            continue\n\n        # Only include text files\n        if path.suffix.lower() in {\".md\", \".txt\", \".org\", \".rst\"}:\n            yield path\n</code></pre>"},{"location":"api/infrastructure/#obsidian_ai.infrastructure.file_system.read_file_safe","title":"read_file_safe","text":"<pre><code>read_file_safe(\n    path: str, start_byte: int = 0, max_bytes: int = 32768\n) -&gt; str\n</code></pre> <p>Safely read a file with error handling.</p> Source code in <code>src/obsidian_ai/infrastructure/file_system.py</code> <pre><code>def read_file_safe(path: str, start_byte: int = 0, max_bytes: int = 32768) -&gt; str:\n    \"\"\"Safely read a file with error handling.\"\"\"\n    try:\n        file_path = _resolve_path(path)\n        with file_path.open(\"rb\") as f:\n            f.seek(max(0, start_byte))\n            data = f.read(max(1, max_bytes))\n        return data.decode(\"utf-8\", errors=\"ignore\")\n    except Exception as e:\n        raise ValueError(f\"Cannot read {path}: {e}\")\n</code></pre>"},{"location":"api/interfaces/","title":"Interfaces API Reference","text":"<p>User-facing interfaces including CLI and chat functionality.</p>"},{"location":"api/interfaces/#cli-interface","title":"CLI Interface","text":""},{"location":"api/interfaces/#obsidian_ai.interfaces.cli","title":"cli","text":""},{"location":"api/interfaces/#obsidian_ai.interfaces.cli.chat","title":"chat","text":"<pre><code>chat(query: str)\n</code></pre> <p>Ask a question about your notes.</p> Source code in <code>src/obsidian_ai/interfaces/cli.py</code> <pre><code>@cli.command()\n@click.argument(\"query\")\ndef chat(query: str):\n    \"\"\"Ask a question about your notes.\"\"\"\n    if not os.getenv(\"OPENAI_API_KEY\"):\n        console.print(\"[red]Error: OPENAI_API_KEY not set[/red]\")\n        sys.exit(1)\n\n    session = ChatSession()\n    response = session.chat_once(query)\n    console.print(response)\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.cli.cli","title":"cli","text":"<pre><code>cli(verbose: int, ignore: tuple[str, ...])\n</code></pre> <p>Obsidian-AI: Chat with your notes.</p> Source code in <code>src/obsidian_ai/interfaces/cli.py</code> <pre><code>@click.group()\n@click.option(\"-v\", \"--verbose\", count=True, help=\"Increase verbosity\")\n@click.option(\"--ignore\", multiple=True, help=\"Additional ignore patterns (can be used multiple times)\")\ndef cli(verbose: int, ignore: tuple[str, ...]):\n    \"\"\"Obsidian-AI: Chat with your notes.\"\"\"\n    setup_logging(verbose)\n\n    # Store additional ignore patterns in environment for config to pick up\n    if ignore:\n        existing = os.getenv(\"OBSIDIAN_AI_IGNORE_PATTERNS\", \"\")\n        new_patterns = \",\".join(ignore)\n        if existing:\n            os.environ[\"OBSIDIAN_AI_IGNORE_PATTERNS\"] = f\"{existing},{new_patterns}\"\n        else:\n            os.environ[\"OBSIDIAN_AI_IGNORE_PATTERNS\"] = new_patterns\n\n        # Clear the cache so config reloads with new patterns\n        from ..infrastructure.config import Config\n\n        Config.load.cache_clear()\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.cli.read","title":"read","text":"<pre><code>read(path: str, start: int, max_bytes: int)\n</code></pre> <p>Read a file from your notes.</p> Source code in <code>src/obsidian_ai/interfaces/cli.py</code> <pre><code>@cli.command()\n@click.argument(\"path\")\n@click.option(\"--start\", default=0, help=\"Start byte\")\n@click.option(\"--max-bytes\", default=4096, help=\"Max bytes to read\")\ndef read(path: str, start: int, max_bytes: int):\n    \"\"\"Read a file from your notes.\"\"\"\n    try:\n        content = read_file_safe(path, start, max_bytes)\n        console.print(content)\n    except Exception as e:\n        console.print(f\"[red]Error: {e}[/red]\")\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.cli.repl","title":"repl","text":"<pre><code>repl()\n</code></pre> <p>Start interactive chat.</p> Source code in <code>src/obsidian_ai/interfaces/cli.py</code> <pre><code>@cli.command()\ndef repl():\n    \"\"\"Start interactive chat.\"\"\"\n    if not os.getenv(\"OPENAI_API_KEY\"):\n        console.print(\"[red]Error: OPENAI_API_KEY not set[/red]\")\n        sys.exit(1)\n\n    session = ChatSession()\n    session.chat_repl()\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.cli.search","title":"search","text":"<pre><code>search(query: str, max_results: int)\n</code></pre> <p>Search notes for keywords.</p> Source code in <code>src/obsidian_ai/interfaces/cli.py</code> <pre><code>@cli.command()\n@click.argument(\"query\")\n@click.option(\"--max-results\", default=10, help=\"Maximum results\")\ndef search(query: str, max_results: int):\n    \"\"\"Search notes for keywords.\"\"\"\n    results = search_engine.search(query, max_results)\n    for result in results:\n        console.print(f\"[blue]{result.relative_path}:{result.line}[/blue] {result.text}\")\n</code></pre>"},{"location":"api/interfaces/#chat-interface","title":"Chat Interface","text":""},{"location":"api/interfaces/#obsidian_ai.interfaces.chat","title":"chat","text":""},{"location":"api/interfaces/#obsidian_ai.interfaces.chat.ChatSession","title":"ChatSession","text":"<p>Manages chat sessions with tool integration and error handling.</p> Source code in <code>src/obsidian_ai/interfaces/chat.py</code> <pre><code>class ChatSession:\n    \"\"\"Manages chat sessions with tool integration and error handling.\"\"\"\n\n    def __init__(self):\n        self.console = Console()\n        self.prompts = ChatPrompts()\n\n    def chat_once(self, query: str, show_tools: bool = False) -&gt; str:\n        \"\"\"Single question-answer chat with optional tool visibility.\"\"\"\n        try:\n            return self._execute_chat(query, show_tools)\n        except Exception as e:\n            logger.error(f\"Chat error: {e}\")\n            return f\"I encountered an error while processing your request: {e}\"\n\n    def _execute_chat(self, query: str, show_tools: bool) -&gt; str:\n        \"\"\"Execute a single chat interaction.\"\"\"\n        messages = [{\"role\": \"system\", \"content\": self.prompts.system_prompt}, {\"role\": \"user\", \"content\": query}]\n\n        try:\n            response = openai_client.chat_completion(messages, tools=TOOLS)\n            message = response.choices[0].message\n\n            # Handle tool calls\n            if message.tool_calls:\n                return self._handle_tool_calls(messages, message, show_tools)\n\n            return message.content or \"No response generated.\"\n\n        except OpenAIError as e:\n            logger.error(f\"OpenAI API error: {e}\")\n            return \"I'm having trouble connecting to the AI service. Please try again.\"\n\n    def _handle_tool_calls(self, messages: list, message: Any, show_tools: bool) -&gt; str:\n        \"\"\"Handle tool calls and get final response.\"\"\"\n        if show_tools:\n            self._display_tool_calls(message.tool_calls)\n\n        # Add assistant message with tool calls\n        messages.append({\"role\": \"assistant\", \"content\": message.content, \"tool_calls\": [tc.model_dump() for tc in message.tool_calls]})\n\n        # Execute tools and add results\n        for tool_call in message.tool_calls:\n            try:\n                result = dispatch_tool(tool_call.function.name, json.loads(tool_call.function.arguments))\n\n                messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": tool_call.id})\n\n                if show_tools:\n                    self._display_tool_result(result)\n\n            except Exception as e:\n                logger.error(f\"Tool execution error: {e}\")\n                messages.append({\"role\": \"tool\", \"content\": json.dumps({\"error\": str(e)}), \"tool_call_id\": tool_call.id})\n\n        # Get final response\n        try:\n            final_response = openai_client.continue_conversation(messages)\n            return final_response or \"No final response generated.\"\n        except OpenAIError as e:\n            logger.error(f\"Error getting final response: {e}\")\n            return \"I found some information but had trouble formulating a response.\"\n\n    def _display_tool_calls(self, tool_calls: list) -&gt; None:\n        \"\"\"Display tool calls to user.\"\"\"\n        for tool_call in tool_calls:\n            try:\n                args = json.loads(tool_call.function.arguments)\n                args_str = \", \".join(f\"{k}={v}\" for k, v in args.items())\n                self.console.print(f\"[yellow]\ud83d\udd27 Calling {tool_call.function.name}({args_str})[/yellow]\")\n            except Exception:\n                self.console.print(f\"[yellow]\ud83d\udd27 Calling {tool_call.function.name}[/yellow]\")\n\n    def _display_tool_result(self, result: str) -&gt; None:\n        \"\"\"Display truncated tool results.\"\"\"\n        display_result = result[:200] + \"...\" if len(result) &gt; 200 else result\n        self.console.print(f\"[dim]   \u2192 {display_result}[/dim]\")\n\n    def chat_repl(self) -&gt; None:\n        \"\"\"Interactive chat loop with error handling.\"\"\"\n        self.console.print(Panel(\"Obsidian-AI Chat. Type 'quit' to exit.\", title=\"Welcome\", border_style=\"blue\"))\n\n        while True:\n            try:\n                query = self.console.input(\"\\n[bold blue]You:[/bold blue] \")\n            except (EOFError, KeyboardInterrupt):\n                break\n\n            if query.strip().lower() in (\"quit\", \"exit\", \"q\"):\n                break\n\n            if not query.strip():\n                continue\n\n            try:\n                response = self.chat_once(query, show_tools=True)\n                self.console.print(Panel(response, title=\"Assistant\", border_style=\"green\"))\n            except Exception as e:\n                logger.error(f\"REPL error: {e}\")\n                self.console.print(f\"[red]Error: {e}[/red]\")\n\n        self.console.print(\"Goodbye!\")\n\n    def update_system_prompt(self, new_prompt: str) -&gt; None:\n        \"\"\"Update the system prompt for this session.\"\"\"\n        self.prompts.update_system_prompt(new_prompt)\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.chat.ChatSession.chat_once","title":"chat_once","text":"<pre><code>chat_once(query: str, show_tools: bool = False) -&gt; str\n</code></pre> <p>Single question-answer chat with optional tool visibility.</p> Source code in <code>src/obsidian_ai/interfaces/chat.py</code> <pre><code>def chat_once(self, query: str, show_tools: bool = False) -&gt; str:\n    \"\"\"Single question-answer chat with optional tool visibility.\"\"\"\n    try:\n        return self._execute_chat(query, show_tools)\n    except Exception as e:\n        logger.error(f\"Chat error: {e}\")\n        return f\"I encountered an error while processing your request: {e}\"\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.chat.ChatSession.chat_repl","title":"chat_repl","text":"<pre><code>chat_repl() -&gt; None\n</code></pre> <p>Interactive chat loop with error handling.</p> Source code in <code>src/obsidian_ai/interfaces/chat.py</code> <pre><code>def chat_repl(self) -&gt; None:\n    \"\"\"Interactive chat loop with error handling.\"\"\"\n    self.console.print(Panel(\"Obsidian-AI Chat. Type 'quit' to exit.\", title=\"Welcome\", border_style=\"blue\"))\n\n    while True:\n        try:\n            query = self.console.input(\"\\n[bold blue]You:[/bold blue] \")\n        except (EOFError, KeyboardInterrupt):\n            break\n\n        if query.strip().lower() in (\"quit\", \"exit\", \"q\"):\n            break\n\n        if not query.strip():\n            continue\n\n        try:\n            response = self.chat_once(query, show_tools=True)\n            self.console.print(Panel(response, title=\"Assistant\", border_style=\"green\"))\n        except Exception as e:\n            logger.error(f\"REPL error: {e}\")\n            self.console.print(f\"[red]Error: {e}[/red]\")\n\n    self.console.print(\"Goodbye!\")\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.chat.ChatSession.update_system_prompt","title":"update_system_prompt","text":"<pre><code>update_system_prompt(new_prompt: str) -&gt; None\n</code></pre> <p>Update the system prompt for this session.</p> Source code in <code>src/obsidian_ai/interfaces/chat.py</code> <pre><code>def update_system_prompt(self, new_prompt: str) -&gt; None:\n    \"\"\"Update the system prompt for this session.\"\"\"\n    self.prompts.update_system_prompt(new_prompt)\n</code></pre>"},{"location":"api/interfaces/#tools-registry","title":"Tools Registry","text":""},{"location":"api/interfaces/#obsidian_ai.interfaces.tools","title":"tools","text":""},{"location":"api/interfaces/#obsidian_ai.interfaces.tools.deep_research_tool","title":"deep_research_tool","text":"<pre><code>deep_research_tool(\n    topic: str, max_iterations: int | None = None\n) -&gt; str\n</code></pre> <p>Comprehensive research with wikilink following and iterative discovery.</p> Source code in <code>src/obsidian_ai/interfaces/tools.py</code> <pre><code>def deep_research_tool(topic: str, max_iterations: int | None = None) -&gt; str:\n    \"\"\"Comprehensive research with wikilink following and iterative discovery.\"\"\"\n    result = research_agent.conduct_research(topic, max_iterations or 4)\n    return json.dumps(result, indent=2)\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.tools.dispatch_tool","title":"dispatch_tool","text":"<pre><code>dispatch_tool(name: str, args: dict[str, Any]) -&gt; str\n</code></pre> <p>Dispatch tool calls to appropriate handlers.</p> Source code in <code>src/obsidian_ai/interfaces/tools.py</code> <pre><code>def dispatch_tool(name: str, args: dict[str, Any]) -&gt; str:\n    \"\"\"Dispatch tool calls to appropriate handlers.\"\"\"\n    match name:\n        case \"search\":\n            return search_tool(args[\"query\"], args.get(\"max_results\"))\n        case \"semantic_search\":\n            return semantic_search_tool(args[\"query\"], args.get(\"k\"))\n        case \"deep_research\":\n            return deep_research_tool(args[\"topic\"], args.get(\"max_iterations\"))\n        case \"read_file\":\n            return read_file_tool(args[\"path\"], args.get(\"start\"), args.get(\"max_bytes\"))\n        case _:\n            return json.dumps({\"error\": f\"Unknown tool: {name}\"})\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.tools.read_file_tool","title":"read_file_tool","text":"<pre><code>read_file_tool(\n    path: str,\n    start: int | None = None,\n    max_bytes: int | None = None,\n) -&gt; str\n</code></pre> <p>Read file content with optional byte range.</p> Source code in <code>src/obsidian_ai/interfaces/tools.py</code> <pre><code>def read_file_tool(path: str, start: int | None = None, max_bytes: int | None = None) -&gt; str:\n    \"\"\"Read file content with optional byte range.\"\"\"\n    try:\n        content = read_file_safe(path, start or 0, max_bytes or 32768)\n        return json.dumps({\"path\": path, \"content\": content, \"start\": start or 0, \"bytes\": len(content.encode())})\n    except Exception as e:\n        return json.dumps({\"error\": str(e)})\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.tools.search_tool","title":"search_tool","text":"<pre><code>search_tool(\n    query: str, max_results: int | None = None\n) -&gt; str\n</code></pre> <p>Enhanced multi-strategy keyword search across notes.</p> Source code in <code>src/obsidian_ai/interfaces/tools.py</code> <pre><code>def search_tool(query: str, max_results: int | None = None) -&gt; str:\n    \"\"\"Enhanced multi-strategy keyword search across notes.\"\"\"\n    return search_engine.search_json(query, max_results or 10)\n</code></pre>"},{"location":"api/interfaces/#obsidian_ai.interfaces.tools.semantic_search_tool","title":"semantic_search_tool","text":"<pre><code>semantic_search_tool(\n    query: str, k: int | None = None\n) -&gt; str\n</code></pre> <p>Semantic similarity search using embeddings.</p> Source code in <code>src/obsidian_ai/interfaces/tools.py</code> <pre><code>def semantic_search_tool(query: str, k: int | None = None) -&gt; str:\n    \"\"\"Semantic similarity search using embeddings.\"\"\"\n    return embedding_service.semantic_search_json(query, k or 10)\n</code></pre>"},{"location":"api/services/","title":"Services API Reference","text":"<p>External service integrations including OpenAI and embedding services.</p>"},{"location":"api/services/#openai-client","title":"OpenAI Client","text":""},{"location":"api/services/#obsidian_ai.services.openai_client","title":"openai_client","text":""},{"location":"api/services/#obsidian_ai.services.openai_client.OpenAIClient","title":"OpenAIClient","text":"<p>Wrapper for OpenAI client with error handling and retries.</p> Source code in <code>src/obsidian_ai/services/openai_client.py</code> <pre><code>class OpenAIClient:\n    \"\"\"Wrapper for OpenAI client with error handling and retries.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.client = OpenAI()\n\n    def chat_completion(\n        self, messages: list[dict[str, str]], tools: list[dict] | None = None, max_tokens: int = 2000, temperature: float = 0.1\n    ) -&gt; ChatCompletion:\n        \"\"\"Create a chat completion with error handling.\"\"\"\n        try:\n            return self.client.chat.completions.create(\n                model=config.model, messages=messages, tools=tools, max_completion_tokens=max_tokens, temperature=temperature\n            )\n        except Exception as e:\n            logger.error(f\"OpenAI API error: {e}\")\n            raise OpenAIError(f\"Failed to get OpenAI response: {e}\") from e\n\n    def simple_completion(self, prompt: str, max_tokens: int = 500) -&gt; str:\n        \"\"\"Get a simple text completion.\"\"\"\n        try:\n            response = self.chat_completion(messages=[{\"role\": \"user\", \"content\": prompt}], max_tokens=max_tokens)\n            return response.choices[0].message.content or \"\"\n        except Exception as e:\n            logger.error(f\"Error in simple completion: {e}\")\n            return f\"Error: Could not process request - {e}\"\n\n    def structured_completion(self, system_prompt: str, user_prompt: str, tools: list[dict] | None = None) -&gt; tuple[str, list[dict] | None]:\n        \"\"\"Get a structured completion with optional tool calls.\"\"\"\n        try:\n            messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n\n            response = self.chat_completion(messages, tools=tools)\n            message = response.choices[0].message\n\n            content = message.content or \"\"\n            tool_calls = [tc.model_dump() for tc in message.tool_calls] if message.tool_calls else None\n\n            return content, tool_calls\n\n        except OpenAIError:\n            raise\n        except Exception as e:\n            logger.error(f\"Error in structured completion: {e}\")\n            return f\"Error: {e}\", None\n\n    def continue_conversation(self, messages: list[dict[str, Any]], tools: list[dict] | None = None) -&gt; str:\n        \"\"\"Continue a conversation with tool results.\"\"\"\n        try:\n            response = self.chat_completion(messages, tools=tools)\n            return response.choices[0].message.content or \"\"\n        except OpenAIError:\n            raise\n        except Exception as e:\n            logger.error(f\"Error continuing conversation: {e}\")\n            return f\"Error: Could not continue conversation - {e}\"\n</code></pre>"},{"location":"api/services/#obsidian_ai.services.openai_client.OpenAIClient.chat_completion","title":"chat_completion","text":"<pre><code>chat_completion(\n    messages: list[dict[str, str]],\n    tools: list[dict] | None = None,\n    max_tokens: int = 2000,\n    temperature: float = 0.1,\n) -&gt; ChatCompletion\n</code></pre> <p>Create a chat completion with error handling.</p> Source code in <code>src/obsidian_ai/services/openai_client.py</code> <pre><code>def chat_completion(\n    self, messages: list[dict[str, str]], tools: list[dict] | None = None, max_tokens: int = 2000, temperature: float = 0.1\n) -&gt; ChatCompletion:\n    \"\"\"Create a chat completion with error handling.\"\"\"\n    try:\n        return self.client.chat.completions.create(\n            model=config.model, messages=messages, tools=tools, max_completion_tokens=max_tokens, temperature=temperature\n        )\n    except Exception as e:\n        logger.error(f\"OpenAI API error: {e}\")\n        raise OpenAIError(f\"Failed to get OpenAI response: {e}\") from e\n</code></pre>"},{"location":"api/services/#obsidian_ai.services.openai_client.OpenAIClient.continue_conversation","title":"continue_conversation","text":"<pre><code>continue_conversation(\n    messages: list[dict[str, Any]],\n    tools: list[dict] | None = None,\n) -&gt; str\n</code></pre> <p>Continue a conversation with tool results.</p> Source code in <code>src/obsidian_ai/services/openai_client.py</code> <pre><code>def continue_conversation(self, messages: list[dict[str, Any]], tools: list[dict] | None = None) -&gt; str:\n    \"\"\"Continue a conversation with tool results.\"\"\"\n    try:\n        response = self.chat_completion(messages, tools=tools)\n        return response.choices[0].message.content or \"\"\n    except OpenAIError:\n        raise\n    except Exception as e:\n        logger.error(f\"Error continuing conversation: {e}\")\n        return f\"Error: Could not continue conversation - {e}\"\n</code></pre>"},{"location":"api/services/#obsidian_ai.services.openai_client.OpenAIClient.simple_completion","title":"simple_completion","text":"<pre><code>simple_completion(\n    prompt: str, max_tokens: int = 500\n) -&gt; str\n</code></pre> <p>Get a simple text completion.</p> Source code in <code>src/obsidian_ai/services/openai_client.py</code> <pre><code>def simple_completion(self, prompt: str, max_tokens: int = 500) -&gt; str:\n    \"\"\"Get a simple text completion.\"\"\"\n    try:\n        response = self.chat_completion(messages=[{\"role\": \"user\", \"content\": prompt}], max_tokens=max_tokens)\n        return response.choices[0].message.content or \"\"\n    except Exception as e:\n        logger.error(f\"Error in simple completion: {e}\")\n        return f\"Error: Could not process request - {e}\"\n</code></pre>"},{"location":"api/services/#obsidian_ai.services.openai_client.OpenAIClient.structured_completion","title":"structured_completion","text":"<pre><code>structured_completion(\n    system_prompt: str,\n    user_prompt: str,\n    tools: list[dict] | None = None,\n) -&gt; tuple[str, list[dict] | None]\n</code></pre> <p>Get a structured completion with optional tool calls.</p> Source code in <code>src/obsidian_ai/services/openai_client.py</code> <pre><code>def structured_completion(self, system_prompt: str, user_prompt: str, tools: list[dict] | None = None) -&gt; tuple[str, list[dict] | None]:\n    \"\"\"Get a structured completion with optional tool calls.\"\"\"\n    try:\n        messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n\n        response = self.chat_completion(messages, tools=tools)\n        message = response.choices[0].message\n\n        content = message.content or \"\"\n        tool_calls = [tc.model_dump() for tc in message.tool_calls] if message.tool_calls else None\n\n        return content, tool_calls\n\n    except OpenAIError:\n        raise\n    except Exception as e:\n        logger.error(f\"Error in structured completion: {e}\")\n        return f\"Error: {e}\", None\n</code></pre>"},{"location":"api/services/#obsidian_ai.services.openai_client.OpenAIError","title":"OpenAIError","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for OpenAI-related errors.</p> Source code in <code>src/obsidian_ai/services/openai_client.py</code> <pre><code>class OpenAIError(Exception):\n    \"\"\"Base exception for OpenAI-related errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/services/#obsidian_ai.services.openai_client.get_openai_client","title":"get_openai_client","text":"<pre><code>get_openai_client() -&gt; OpenAIClient\n</code></pre> <p>Get the global OpenAI client instance.</p> Source code in <code>src/obsidian_ai/services/openai_client.py</code> <pre><code>def get_openai_client() -&gt; OpenAIClient:\n    \"\"\"Get the global OpenAI client instance.\"\"\"\n    global _openai_client\n    if _openai_client is None:\n        _openai_client = OpenAIClient()\n    return _openai_client\n</code></pre>"},{"location":"api/services/#embedding-service","title":"Embedding Service","text":""},{"location":"api/services/#obsidian_ai.services.embedding_service","title":"embedding_service","text":""},{"location":"api/services/#obsidian_ai.services.embedding_service.EmbeddingService","title":"EmbeddingService","text":"<p>Service for semantic search using local embeddings.</p> Source code in <code>src/obsidian_ai/services/embedding_service.py</code> <pre><code>class EmbeddingService:\n    \"\"\"Service for semantic search using local embeddings.\"\"\"\n\n    def __init__(self) -&gt; None:\n        pass\n\n    def semantic_search(self, query: str, k: int = 10) -&gt; dict[str, Any]:\n        \"\"\"Perform semantic search and return structured results.\"\"\"\n        try:\n            result_json = _semantic_search(query, k)\n            return json.loads(result_json)\n        except Exception as e:\n            return {\"query\": query, \"results\": [], \"error\": str(e)}\n\n    def semantic_search_json(self, query: str, k: int = 10) -&gt; str:\n        \"\"\"Perform semantic search and return JSON string.\"\"\"\n        result = self.semantic_search(query, k)\n        return json.dumps(result)\n</code></pre>"},{"location":"api/services/#obsidian_ai.services.embedding_service.EmbeddingService.semantic_search","title":"semantic_search","text":"<pre><code>semantic_search(query: str, k: int = 10) -&gt; dict[str, Any]\n</code></pre> <p>Perform semantic search and return structured results.</p> Source code in <code>src/obsidian_ai/services/embedding_service.py</code> <pre><code>def semantic_search(self, query: str, k: int = 10) -&gt; dict[str, Any]:\n    \"\"\"Perform semantic search and return structured results.\"\"\"\n    try:\n        result_json = _semantic_search(query, k)\n        return json.loads(result_json)\n    except Exception as e:\n        return {\"query\": query, \"results\": [], \"error\": str(e)}\n</code></pre>"},{"location":"api/services/#obsidian_ai.services.embedding_service.EmbeddingService.semantic_search_json","title":"semantic_search_json","text":"<pre><code>semantic_search_json(query: str, k: int = 10) -&gt; str\n</code></pre> <p>Perform semantic search and return JSON string.</p> Source code in <code>src/obsidian_ai/services/embedding_service.py</code> <pre><code>def semantic_search_json(self, query: str, k: int = 10) -&gt; str:\n    \"\"\"Perform semantic search and return JSON string.\"\"\"\n    result = self.semantic_search(query, k)\n    return json.dumps(result)\n</code></pre>"},{"location":"developer/architecture/","title":"Architecture Overview","text":"<p>Obsidian-AI is designed with a modular, bacterial-inspired architecture that emphasizes small, composable, and easily transferable components.</p>"},{"location":"developer/architecture/#core-principles","title":"Core Principles","text":""},{"location":"developer/architecture/#bacterial-code-philosophy","title":"Bacterial Code Philosophy","text":"<p>Our codebase follows bacterial coding principles:</p> <ul> <li>Small modules: Each component is self-contained and focused</li> <li>Horizontal gene transfer: Code can be easily \"copy-pasted\" between projects  </li> <li>Energy efficiency: Every line of code serves a purpose</li> <li>Rapid adaptation: Easy to modify and extend</li> </ul>"},{"location":"developer/architecture/#design-patterns","title":"Design Patterns","text":"<ul> <li>Dependency injection for loose coupling</li> <li>Protocol-based interfaces for flexibility</li> <li>Functional programming where appropriate</li> <li>Immutable data structures using dataclasses</li> </ul>"},{"location":"developer/architecture/#system-architecture","title":"System Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Interfaces    \u2502    \u2502      Core       \u2502    \u2502  Infrastructure \u2502\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\n\u2502 \u2022 CLI           \u2502\u2500\u2500\u2500\u2500\u2502 \u2022 Research      \u2502\u2500\u2500\u2500\u2500\u2502 \u2022 Config        \u2502\n\u2502 \u2022 Chat          \u2502    \u2502 \u2022 Search        \u2502    \u2502 \u2022 File System   \u2502\n\u2502 \u2022 Tools         \u2502    \u2502 \u2022 WikiLinks     \u2502    \u2502 \u2022 Logging       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502    Services     \u2502\n                    \u2502                 \u2502\n                    \u2502 \u2022 OpenAI        \u2502\n                    \u2502 \u2022 Embeddings    \u2502\n                    \u2502 \u2022 Search Engine \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer/architecture/#module-breakdown","title":"Module Breakdown","text":""},{"location":"developer/architecture/#core-srcobsidian_aicore","title":"Core (<code>src/obsidian_ai/core/</code>)","text":"<p>Contains the main business logic:</p>"},{"location":"developer/architecture/#research-agent-research_agentpy","title":"Research Agent (<code>research_agent.py</code>)","text":"<ul> <li>Multi-step reasoning engine</li> <li>Context synthesis and analysis</li> <li>Report generation</li> </ul>"},{"location":"developer/architecture/#search-engine-search_enginepy","title":"Search Engine (<code>search_engine.py</code>)","text":"<ul> <li>Unified search interface</li> <li>Multiple search strategies:</li> <li>Exact phrase matching</li> <li>Keyword-based search</li> <li>Filename search</li> <li>Result ranking and deduplication</li> </ul>"},{"location":"developer/architecture/#wikilink-parser-wikilink_parserpy","title":"WikiLink Parser (<code>wikilink_parser.py</code>)","text":"<ul> <li>Parses WikiLink syntax <code>[[Link]]</code> and <code>[[Link|Display]]</code></li> <li>Handles nested brackets</li> <li>Extracts key terms for search</li> </ul>"},{"location":"developer/architecture/#infrastructure-srcobsidian_aiinfrastructure","title":"Infrastructure (<code>src/obsidian_ai/infrastructure/</code>)","text":"<p>Provides foundational services:</p>"},{"location":"developer/architecture/#configuration-configpy","title":"Configuration (<code>config.py</code>)","text":"<pre><code>@dataclass(frozen=True)\nclass Config:\n    brain_dir: Path\n    model: str\n    max_tool_calls: int\n    cache_dir: Path\n    ignore_patterns: list[str]\n</code></pre>"},{"location":"developer/architecture/#file-system-file_systempy","title":"File System (<code>file_system.py</code>)","text":"<ul> <li>Safe file operations with security checks</li> <li>Text file discovery with ignore patterns</li> <li>Path resolution and validation</li> </ul>"},{"location":"developer/architecture/#services-srcobsidian_aiservices","title":"Services (<code>src/obsidian_ai/services/</code>)","text":"<p>External service integrations:</p>"},{"location":"developer/architecture/#openai-client-openai_clientpy","title":"OpenAI Client (<code>openai_client.py</code>)","text":"<ul> <li>Lazy initialization to avoid import-time API calls</li> <li>Comprehensive error handling</li> <li>Multiple completion types (simple, structured, conversational)</li> </ul>"},{"location":"developer/architecture/#embedding-service-embedding_servicepy","title":"Embedding Service (<code>embedding_service.py</code>)","text":"<ul> <li>Local embedding generation</li> <li>Semantic search capabilities</li> <li>Caching for performance</li> </ul>"},{"location":"developer/architecture/#interfaces-srcobsidian_aiinterfaces","title":"Interfaces (<code>src/obsidian_ai/interfaces/</code>)","text":"<p>User-facing interfaces:</p>"},{"location":"developer/architecture/#cli-clipy","title":"CLI (<code>cli.py</code>)","text":"<ul> <li>Command-line interface using Typer</li> <li>Subcommands for different operations</li> <li>Rich formatting for output</li> </ul>"},{"location":"developer/architecture/#chat-chatpy","title":"Chat (<code>chat.py</code>)","text":"<ul> <li>Interactive chat sessions</li> <li>Context management</li> <li>Tool integration</li> </ul>"},{"location":"developer/architecture/#tools-toolspy","title":"Tools (<code>tools.py</code>)","text":"<ul> <li>Tool definitions for AI agent</li> <li>File operations and search functions</li> </ul>"},{"location":"developer/architecture/#prompts-srcobsidian_aiprompts","title":"Prompts (<code>src/obsidian_ai/prompts/</code>)","text":"<p>AI prompt management:</p>"},{"location":"developer/architecture/#base-basepy","title":"Base (<code>base.py</code>)","text":"<ul> <li>Template management system</li> <li>Variable substitution</li> <li>Environment-based overrides</li> </ul>"},{"location":"developer/architecture/#chat-research-chatpy-researchpy","title":"Chat &amp; Research (<code>chat.py</code>, <code>research.py</code>)","text":"<ul> <li>Specialized prompts for different use cases</li> <li>Configurable via environment variables</li> </ul>"},{"location":"developer/architecture/#data-flow","title":"Data Flow","text":""},{"location":"developer/architecture/#search-request-flow","title":"Search Request Flow","text":"<ol> <li>User input \u2192 CLI interface</li> <li>Query parsing \u2192 Search engine</li> <li>Multiple strategies \u2192 Exact phrase, keyword, filename search</li> <li>Result aggregation \u2192 Deduplication and ranking  </li> <li>Response formatting \u2192 JSON or text output</li> </ol>"},{"location":"developer/architecture/#research-flow","title":"Research Flow","text":"<ol> <li>Topic analysis \u2192 Extract key concepts</li> <li>Information gathering \u2192 Search knowledge base</li> <li>Context synthesis \u2192 Combine relevant information</li> <li>Report generation \u2192 Structured output with sources</li> </ol>"},{"location":"developer/architecture/#chat-flow","title":"Chat Flow","text":"<ol> <li>Message processing \u2192 Parse user input</li> <li>Context retrieval \u2192 Search relevant knowledge</li> <li>Response generation \u2192 AI completion with context</li> <li>Tool execution \u2192 File operations if needed</li> </ol>"},{"location":"developer/architecture/#security-considerations","title":"Security Considerations","text":""},{"location":"developer/architecture/#file-system-security","title":"File System Security","text":"<ul> <li>Path traversal prevention</li> <li>Sandbox to brain directory</li> <li>File existence validation</li> </ul>"},{"location":"developer/architecture/#api-security","title":"API Security","text":"<ul> <li>Safe API key handling</li> <li>Rate limiting considerations</li> <li>Error message sanitization</li> </ul>"},{"location":"developer/architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"developer/architecture/#search-performance","title":"Search Performance","text":"<ul> <li>File discovery: O(n) where n = number of files</li> <li>Text search: O(m) where m = total content size</li> <li>Result ranking: O(k log k) where k = number of results</li> </ul>"},{"location":"developer/architecture/#memory-usage","title":"Memory Usage","text":"<ul> <li>Lazy loading of file contents</li> <li>Streaming for large files</li> <li>Caching for frequently accessed data</li> </ul>"},{"location":"developer/architecture/#scalability","title":"Scalability","text":"<ul> <li>Designed for personal knowledge bases (&lt; 10k files)</li> <li>Can handle large individual files (up to 2MB default)</li> <li>Configurable limits for different use cases</li> </ul>"},{"location":"developer/architecture/#extension-points","title":"Extension Points","text":""},{"location":"developer/architecture/#adding-new-search-strategies","title":"Adding New Search Strategies","text":"<pre><code>class CustomSearch:\n    def search(self, query: str, max_results: int) -&gt; list[SearchResult]:\n        # Implementation here\n        pass\n\n# Add to UnifiedSearchEngine\nengine.strategies.append(CustomSearch())\n</code></pre>"},{"location":"developer/architecture/#custom-file-processors","title":"Custom File Processors","text":"<pre><code>def custom_processor(path: Path) -&gt; str:\n    # Process file and return text content\n    pass\n\n# Register with file system\nregister_processor(\".custom\", custom_processor)\n</code></pre>"},{"location":"developer/architecture/#new-ai-models","title":"New AI Models","text":"<pre><code>class CustomClient:\n    def simple_completion(self, prompt: str) -&gt; str:\n        # Implementation for custom model\n        pass\n</code></pre> <p>This architecture enables easy testing, maintenance, and extension while keeping the codebase modular and focused.</p>"},{"location":"developer/contributing/","title":"Contributing to Obsidian-AI","text":"<p>We welcome contributions to Obsidian-AI! This guide will help you get started.</p>"},{"location":"developer/contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/sumukshashidhar/obsidian-ai.git\ncd obsidian-ai\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>uv sync\n</code></pre></p> </li> <li> <p>Set up pre-commit hooks:    <pre><code>uv run pre-commit install\n</code></pre></p> </li> </ol>"},{"location":"developer/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"developer/contributing/#code-style","title":"Code Style","text":"<p>We follow bacterial coding principles:</p> <ul> <li>Small functions (20 lines max)</li> <li>Single responsibility per function</li> <li>Self-documenting code with verbose variable names</li> <li>Early returns and exception bubbling</li> </ul>"},{"location":"developer/contributing/#code-standards","title":"Code Standards","text":"<ul> <li>Use Python 3.12+ features aggressively</li> <li>Type annotations everywhere</li> <li>Dataclasses for data structures</li> <li>Modern Python syntax (walrus operator, union types, etc.)</li> </ul>"},{"location":"developer/contributing/#testing","title":"Testing","text":"<p>Run the test suite:</p> <pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=src/obsidian_ai --cov-report=term-missing\n\n# Run specific test files\nuv run pytest tests/test_core.py -v\n</code></pre>"},{"location":"developer/contributing/#linting-and-formatting","title":"Linting and Formatting","text":"<pre><code># Check linting\nuv run ruff check src/ tests/\n\n# Auto-fix issues\nuv run ruff check --fix src/ tests/\n\n# Format code\nuv run ruff format src/ tests/\n\n# Type checking\nuv run mypy src/\n</code></pre>"},{"location":"developer/contributing/#contribution-guidelines","title":"Contribution Guidelines","text":""},{"location":"developer/contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch from <code>main</code></li> <li>Make your changes</li> <li>Add tests for new functionality</li> <li>Run the test suite and linting</li> <li>Submit a pull request</li> </ol>"},{"location":"developer/contributing/#commit-message-format","title":"Commit Message Format","text":"<p>Use conventional commit format:</p> <pre><code>feat: add semantic search functionality\nfix: resolve wikilink parsing edge case\ndocs: update installation instructions\ntest: add integration tests for search engine\n</code></pre>"},{"location":"developer/contributing/#code-review-checklist","title":"Code Review Checklist","text":"<ul> <li>[ ] Tests pass locally</li> <li>[ ] Code follows style guidelines</li> <li>[ ] New features have tests</li> <li>[ ] Documentation is updated</li> <li>[ ] No breaking changes (or properly documented)</li> </ul>"},{"location":"developer/contributing/#areas-for-contribution","title":"Areas for Contribution","text":""},{"location":"developer/contributing/#high-priority","title":"High Priority","text":"<ul> <li>Performance optimization for large knowledge bases</li> <li>Additional file format support (org-mode, rst, etc.)</li> <li>Enhanced AI reasoning capabilities</li> <li>Better error handling and user feedback</li> </ul>"},{"location":"developer/contributing/#medium-priority","title":"Medium Priority","text":"<ul> <li>GUI interface development</li> <li>Plugin system for extensibility</li> <li>Cloud sync capabilities</li> <li>Mobile app companion</li> </ul>"},{"location":"developer/contributing/#low-priority","title":"Low Priority","text":"<ul> <li>Additional language models support</li> <li>Custom embedding models</li> <li>Advanced visualization features</li> </ul>"},{"location":"developer/contributing/#development-tips","title":"Development Tips","text":""},{"location":"developer/contributing/#code-organization","title":"Code Organization","text":"<pre><code>src/obsidian_ai/\n\u251c\u2500\u2500 core/           # Core business logic\n\u251c\u2500\u2500 infrastructure/ # Configuration, file system\n\u251c\u2500\u2500 interfaces/     # CLI, API interfaces\n\u251c\u2500\u2500 services/       # External service integrations\n\u2514\u2500\u2500 prompts/        # AI prompt management\n</code></pre>"},{"location":"developer/contributing/#testing-philosophy","title":"Testing Philosophy","text":"<ul> <li>Unit tests for individual functions</li> <li>Integration tests for component interactions</li> <li>End-to-end tests for complete workflows</li> <li>Synthetic data for reproducible tests</li> </ul>"},{"location":"developer/contributing/#debugging","title":"Debugging","text":"<p>Use the built-in logging:</p> <pre><code>from loguru import logger\n\nlogger.debug(\"Debug information\")\nlogger.info(\"Important info\")\nlogger.error(\"Error occurred\")\n</code></pre>"},{"location":"developer/contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Issues: Report bugs and request features on GitHub Issues</li> <li>Discussions: Join conversations in GitHub Discussions</li> <li>Documentation: Check our architecture guide for technical details</li> </ul> <p>Thank you for contributing to Obsidian-AI!</p>"},{"location":"developer/testing/","title":"Testing Guide","text":"<p>Obsidian-AI maintains a comprehensive test suite with 102+ tests achieving high code coverage. This guide covers our testing philosophy, practices, and tools.</p>"},{"location":"developer/testing/#testing-philosophy","title":"Testing Philosophy","text":""},{"location":"developer/testing/#bacterial-testing-approach","title":"Bacterial Testing Approach","text":"<p>Following our bacterial coding principles:</p> <ul> <li>Small, focused tests - Each test has one clear purpose</li> <li>Synthetic test data - Reproducible, controlled test environments</li> <li>Copy-pasteable fixtures - Reusable test components</li> <li>Fast execution - Tests run quickly for rapid feedback</li> </ul>"},{"location":"developer/testing/#test-pyramid","title":"Test Pyramid","text":"<pre><code>           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n           \u2502 E2E Tests   \u2502 (Few, slow, realistic)\n           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502 Integration     \u2502 (Some, medium, component interactions)\n         \u2502 Tests           \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502 Unit Tests          \u2502 (Many, fast, isolated)\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer/testing/#test-structure","title":"Test Structure","text":""},{"location":"developer/testing/#current-test-coverage","title":"Current Test Coverage","text":"<ul> <li>102 tests passing</li> <li>49% overall coverage</li> <li>100% coverage for core components:</li> <li>WikiLink parser</li> <li>Configuration system</li> <li>File system operations</li> <li>93% coverage for search engine</li> <li>95%+ coverage for prompt management</li> </ul>"},{"location":"developer/testing/#test-organization","title":"Test Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # Shared fixtures\n\u251c\u2500\u2500 test_core.py             # Core business logic tests\n\u251c\u2500\u2500 test_infrastructure.py   # Config and file system tests\n\u251c\u2500\u2500 test_services.py         # External service tests\n\u251c\u2500\u2500 test_interfaces.py       # CLI and API tests\n\u251c\u2500\u2500 test_prompts.py          # Prompt management tests\n\u251c\u2500\u2500 test_search_engine.py    # Search functionality tests\n\u2514\u2500\u2500 test_wikilink_parser.py  # WikiLink parsing tests\n</code></pre>"},{"location":"developer/testing/#running-tests","title":"Running Tests","text":""},{"location":"developer/testing/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with verbose output\nuv run pytest -v\n\n# Run specific test file\nuv run pytest tests/test_core.py\n\n# Run specific test\nuv run pytest tests/test_core.py::TestWikilinkParser::test_extract_wikilinks_simple\n</code></pre>"},{"location":"developer/testing/#coverage-analysis","title":"Coverage Analysis","text":"<pre><code># Run with coverage\nuv run pytest --cov=src/obsidian_ai --cov-report=term-missing\n\n# Generate HTML coverage report\nuv run pytest --cov=src/obsidian_ai --cov-report=html\n\n# Coverage for specific module\nuv run pytest --cov=src/obsidian_ai.core --cov-report=term-missing tests/test_core.py\n</code></pre>"},{"location":"developer/testing/#test-selection","title":"Test Selection","text":"<pre><code># Run only fast tests\nuv run pytest -m \"not slow\"\n\n# Run only integration tests\nuv run pytest -k \"integration\"\n\n# Run failed tests from last run\nuv run pytest --lf\n</code></pre>"},{"location":"developer/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"developer/testing/#test-structure-pattern","title":"Test Structure Pattern","text":"<pre><code>class TestComponent:\n    def test_specific_behavior(self):\n        # Arrange\n        input_data = create_test_data()\n\n        # Act\n        result = component.method(input_data)\n\n        # Assert\n        assert result == expected_output\n</code></pre>"},{"location":"developer/testing/#fixtures-and-test-data","title":"Fixtures and Test Data","text":""},{"location":"developer/testing/#synthetic-knowledge-base","title":"Synthetic Knowledge Base","text":"<p>The <code>temp_brain</code> fixture creates a comprehensive synthetic knowledge base:</p> <pre><code>@pytest.fixture\ndef temp_brain():\n    \"\"\"Create temporary brain directory with synthetic test data.\"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        brain_dir = Path(tmpdir) / \"brain\"\n        brain_dir.mkdir()\n        create_synthetic_notes(brain_dir)\n        yield brain_dir\n</code></pre>"},{"location":"developer/testing/#mock-services","title":"Mock Services","text":"<pre><code>@pytest.fixture\ndef mock_openai_client():\n    \"\"\"Mock OpenAI client for testing.\"\"\"\n    with patch(\"obsidian_ai.services.openai_client.OpenAI\") as mock_openai:\n        mock_client = mock_openai.return_value\n        mock_client.chat.completions.create.return_value.choices = [\n            type(\"Choice\", (), {\"message\": type(\"Message\", (), {\"content\": \"Test response\"})()})()\n        ]\n        yield mock_client\n</code></pre>"},{"location":"developer/testing/#testing-strategies","title":"Testing Strategies","text":""},{"location":"developer/testing/#unit-testing","title":"Unit Testing","text":"<p>Test individual functions in isolation:</p> <pre><code>def test_extract_wikilinks_simple():\n    text = \"This mentions [[John Smith]] and [[Machine Learning]].\"\n\n    links = WikiLinkParser.extract_wikilinks(text)\n\n    assert len(links) == 2\n    assert links[0].target == \"John Smith\"\n    assert links[1].target == \"Machine Learning\"\n</code></pre>"},{"location":"developer/testing/#integration-testing","title":"Integration Testing","text":"<p>Test component interactions:</p> <pre><code>def test_search_integration(temp_brain):\n    \"\"\"Test search engine with actual file system.\"\"\"\n    from obsidian_ai.infrastructure.config import Config\n\n    test_config = Config(\n        brain_dir=temp_brain,\n        model=\"gpt-4o\",\n        max_tool_calls=5,\n        cache_dir=temp_brain / \".cache\",\n        ignore_patterns=[\".git\", \"__pycache__\"]\n    )\n\n    with patch(\"obsidian_ai.core.search_engine.config\", test_config):\n        search = ExactPhraseSearch()\n        results = search.search(\"Tara\", max_results=10)\n\n    assert len(results) &gt;= 1\n    assert any(\"Tara\" in result.text for result in results)\n</code></pre>"},{"location":"developer/testing/#mocking-external-dependencies","title":"Mocking External Dependencies","text":"<pre><code>@patch(\"obsidian_ai.services.openai_client.OpenAI\")\ndef test_openai_error_handling(mock_openai):\n    mock_openai.return_value.chat.completions.create.side_effect = Exception(\"API Error\")\n\n    with patch.dict(os.environ, {\"OPENAI_API_KEY\": \"test-key\"}):\n        client = OpenAIClient()\n        result = client.simple_completion(\"test prompt\")\n\n    assert \"Error:\" in result\n</code></pre>"},{"location":"developer/testing/#test-data-management","title":"Test Data Management","text":""},{"location":"developer/testing/#synthetic-knowledge-base-structure","title":"Synthetic Knowledge Base Structure","text":"<p>Our test data simulates a realistic knowledge base:</p> <pre><code>brain/\n\u251c\u2500\u2500 daily/\n\u2502   \u251c\u2500\u2500 2024-01-15.md     # Daily notes with tasks and meetings\n\u2502   \u2514\u2500\u2500 2024-01-16.md\n\u251c\u2500\u2500 people/\n\u2502   \u251c\u2500\u2500 john-smith.md     # Person profiles with connections\n\u2502   \u2514\u2500\u2500 sarah-wilson.md\n\u251c\u2500\u2500 projects/\n\u2502   \u251c\u2500\u2500 machine-learning.md  # Project documentation\n\u2502   \u2514\u2500\u2500 data-pipeline.md\n\u251c\u2500\u2500 concepts/\n\u2502   \u251c\u2500\u2500 deep-learning.md     # Concept explanations\n\u2502   \u2514\u2500\u2500 neural-networks.md\n\u2514\u2500\u2500 research/\n    \u2514\u2500\u2500 paper-ideas.md       # Research notes\n</code></pre>"},{"location":"developer/testing/#test-data-characteristics","title":"Test Data Characteristics","text":"<ul> <li>Rich interconnections with WikiLinks</li> <li>Realistic content mimicking actual knowledge bases</li> <li>Edge cases like special characters, Unicode, large files</li> <li>Hierarchical structure with subdirectories</li> </ul>"},{"location":"developer/testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"developer/testing/#common-issues","title":"Common Issues","text":""},{"location":"developer/testing/#test-isolation","title":"Test Isolation","text":"<pre><code># Good: Use fixtures for clean state\ndef test_with_fixture(temp_brain):\n    # Test uses isolated temporary directory\n    pass\n\n# Bad: Tests depend on global state\ndef test_without_fixture():\n    # Test modifies shared resources\n    pass\n</code></pre>"},{"location":"developer/testing/#mock-configuration","title":"Mock Configuration","text":"<pre><code># Good: Patch at the right level\nwith patch(\"module.where.used.config\", test_config):\n    result = function_under_test()\n\n# Bad: Patch at import level\nwith patch(\"module.where.defined.config\", test_config):\n    # Won't work if already imported\n    pass\n</code></pre>"},{"location":"developer/testing/#debugging-techniques","title":"Debugging Techniques","text":""},{"location":"developer/testing/#print-debugging","title":"Print Debugging","text":"<pre><code>def test_with_debug():\n    result = function_under_test()\n    print(f\"Debug: result = {result}\")  # Use pytest -s to see output\n    assert result == expected\n</code></pre>"},{"location":"developer/testing/#pytest-debugging","title":"Pytest Debugging","text":"<pre><code># Drop into debugger on failure\nuv run pytest --pdb\n\n# Drop into debugger immediately\nuv run pytest --pdb-trace\n\n# Show local variables in traceback\nuv run pytest -l\n</code></pre>"},{"location":"developer/testing/#performance-testing","title":"Performance Testing","text":""},{"location":"developer/testing/#timing-tests","title":"Timing Tests","text":"<pre><code>import time\n\ndef test_performance():\n    start = time.time()\n    result = expensive_operation()\n    duration = time.time() - start\n\n    assert duration &lt; 1.0  # Should complete within 1 second\n    assert result is not None\n</code></pre>"},{"location":"developer/testing/#memory-testing","title":"Memory Testing","text":"<pre><code>import psutil\nimport os\n\ndef test_memory_usage():\n    process = psutil.Process(os.getpid())\n    initial_memory = process.memory_info().rss\n\n    result = memory_intensive_operation()\n\n    final_memory = process.memory_info().rss\n    memory_increase = final_memory - initial_memory\n\n    assert memory_increase &lt; 100 * 1024 * 1024  # Less than 100MB increase\n</code></pre>"},{"location":"developer/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"developer/testing/#github-actions-integration","title":"GitHub Actions Integration","text":"<p>Our CI pipeline runs: 1. Linting with ruff 2. Type checking with mypy 3. Test execution with pytest 4. Coverage reporting 5. Documentation building</p>"},{"location":"developer/testing/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n</code></pre>"},{"location":"developer/testing/#best-practices","title":"Best Practices","text":""},{"location":"developer/testing/#dos","title":"Do's","text":"<ul> <li>\u2705 Write tests before fixing bugs</li> <li>\u2705 Use descriptive test names</li> <li>\u2705 Keep tests independent</li> <li>\u2705 Mock external dependencies</li> <li>\u2705 Test edge cases and error conditions</li> </ul>"},{"location":"developer/testing/#donts","title":"Don'ts","text":"<ul> <li>\u274c Test implementation details</li> <li>\u274c Write overly complex tests</li> <li>\u274c Ignore flaky tests</li> <li>\u274c Skip testing error paths</li> <li>\u274c Use production data in tests</li> </ul>"},{"location":"developer/testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer/testing/#common-test-failures","title":"Common Test Failures","text":""},{"location":"developer/testing/#import-errors","title":"Import Errors","text":"<pre><code># Fix: Ensure package is properly installed\nuv sync\n\n# Or run tests with PYTHONPATH\nPYTHONPATH=src uv run pytest\n</code></pre>"},{"location":"developer/testing/#mock-issues","title":"Mock Issues","text":"<pre><code># Fix: Patch where the object is used, not where it's defined\n# Wrong: patch(\"requests.get\")\n# Right: patch(\"mymodule.requests.get\")\n</code></pre>"},{"location":"developer/testing/#file-system-tests","title":"File System Tests","text":"<pre><code># Fix: Use proper temporary directories\ndef test_file_operations(tmp_path):\n    test_file = tmp_path / \"test.md\"\n    test_file.write_text(\"content\")\n    # Test uses isolated filesystem\n</code></pre> <p>For more debugging help, see our contribution guide or check the architecture documentation.</p>"},{"location":"user-guide/configuration/","title":"Configuration","text":"<p>Obsidian-AI is designed to work out of the box with minimal configuration. This guide covers all available configuration options.</p>"},{"location":"user-guide/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"user-guide/configuration/#required-settings","title":"Required Settings","text":"Variable Description Example <code>OPENAI_API_KEY</code> Your OpenAI API key <code>sk-proj-...</code>"},{"location":"user-guide/configuration/#optional-settings","title":"Optional Settings","text":"Variable Default Description <code>OBSIDIAN_AI_BRAIN_DIR</code> <code>~/brain</code> Directory containing your notes <code>OBSIDIAN_AI_MODEL</code> <code>gpt-4o</code> OpenAI model to use <code>OBSIDIAN_AI_MAX_TOOL_CALLS</code> <code>5</code> Maximum tool calls per query <code>OBSIDIAN_AI_IGNORE_PATTERNS</code> See below Comma-separated patterns to ignore"},{"location":"user-guide/configuration/#brain-directory-setup","title":"Brain Directory Setup","text":"<p>Your brain directory should contain your notes in supported formats:</p> <pre><code>brain/\n\u251c\u2500\u2500 projects/\n\u2502   \u251c\u2500\u2500 project-alpha.md\n\u2502   \u2514\u2500\u2500 project-beta.md\n\u251c\u2500\u2500 people/\n\u2502   \u251c\u2500\u2500 john-smith.md\n\u2502   \u2514\u2500\u2500 sarah-wilson.md\n\u251c\u2500\u2500 daily/\n\u2502   \u251c\u2500\u2500 2024-01-15.md\n\u2502   \u2514\u2500\u2500 2024-01-16.md\n\u2514\u2500\u2500 concepts/\n    \u251c\u2500\u2500 machine-learning.md\n    \u2514\u2500\u2500 deep-learning.md\n</code></pre>"},{"location":"user-guide/configuration/#supported-file-types","title":"Supported File Types","text":"<ul> <li>Markdown: <code>.md</code></li> <li>Text: <code>.txt</code></li> <li>Org-mode: <code>.org</code></li> <li>reStructuredText: <code>.rst</code></li> <li>Code files: <code>.py</code>, <code>.js</code>, <code>.ts</code>, <code>.java</code>, <code>.go</code></li> <li>Data files: <code>.csv</code>, <code>.json</code>, <code>.yaml</code>, <code>.yml</code></li> </ul>"},{"location":"user-guide/configuration/#ignore-patterns","title":"Ignore Patterns","text":"<p>Control which files and directories are excluded from processing.</p>"},{"location":"user-guide/configuration/#default-ignore-patterns","title":"Default Ignore Patterns","text":"<p>These patterns are always ignored:</p> <ul> <li><code>.git</code> - Git repositories</li> <li><code>.obsidian</code> - Obsidian app files</li> <li><code>.obsidian_ai_cache</code> - Cache directory</li> <li><code>node_modules</code> - Node.js dependencies</li> <li><code>__pycache__</code> - Python cache</li> <li><code>.DS_Store</code> - macOS metadata</li> <li><code>Thumbs.db</code> - Windows metadata</li> </ul>"},{"location":"user-guide/configuration/#custom-ignore-patterns","title":"Custom Ignore Patterns","text":"<p>Add your own patterns via environment variable:</p> <pre><code>export OBSIDIAN_AI_IGNORE_PATTERNS=\"temp/*,*.draft,private/*,30. Areas/Roleplay\"\n</code></pre> <p>Or use command-line flags for session-specific ignoring:</p> <pre><code>obsidian-ai --ignore \"temp/*\" --ignore \"*.draft\" search \"project ideas\"\n</code></pre>"},{"location":"user-guide/configuration/#pattern-syntax","title":"Pattern Syntax","text":"<ul> <li><code>*</code> matches any characters: <code>temp/*</code> ignores anything in temp directories</li> <li><code>*.ext</code> matches files with specific extensions</li> <li><code>dirname</code> matches exact directory names anywhere in the path</li> <li><code>path/to/dir</code> matches specific paths relative to brain directory</li> </ul>"},{"location":"user-guide/configuration/#examples","title":"Examples","text":"<pre><code># Ignore temporary files\nexport OBSIDIAN_AI_IGNORE_PATTERNS=\"*.tmp,*.temp\"\n\n# Ignore specific directories\nexport OBSIDIAN_AI_IGNORE_PATTERNS=\"archive/*,old-notes/*\"\n\n# Ignore private content\nexport OBSIDIAN_AI_IGNORE_PATTERNS=\"private/*,personal/*,diary/*\"\n\n# Complex patterns\nexport OBSIDIAN_AI_IGNORE_PATTERNS=\"*.draft,temp/*,archive/*,30. Areas/Roleplay\"\n</code></pre>"},{"location":"user-guide/configuration/#model-selection","title":"Model Selection","text":"<p>Choose the OpenAI model that best fits your needs:</p>"},{"location":"user-guide/configuration/#available-models","title":"Available Models","text":"Model Description Best For <code>gpt-4o</code> Latest GPT-4 (default) Complex reasoning, analysis <code>gpt-4</code> Standard GPT-4 High-quality responses <code>gpt-3.5-turbo</code> Faster, less expensive Quick queries, simple tasks"},{"location":"user-guide/configuration/#configuration_1","title":"Configuration","text":"<pre><code># High quality (default)\nexport OBSIDIAN_AI_MODEL=\"gpt-4o\"\n\n# Fast and economical\nexport OBSIDIAN_AI_MODEL=\"gpt-3.5-turbo\"\n\n# Standard GPT-4\nexport OBSIDIAN_AI_MODEL=\"gpt-4\"\n</code></pre>"},{"location":"user-guide/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"user-guide/configuration/#file-size-limits","title":"File Size Limits","text":"<p>Large files are automatically skipped to prevent performance issues:</p> <ul> <li>Default limit: 2MB per file</li> <li>Files exceeding the limit are ignored</li> <li>This prevents processing of large binary files or exports</li> </ul>"},{"location":"user-guide/configuration/#cache-configuration","title":"Cache Configuration","text":"<p>Obsidian-AI caches embeddings and search indices for better performance:</p> <pre><code>.obsidian_ai_cache/\n\u251c\u2500\u2500 embeddings/     # TF-IDF vectors\n\u251c\u2500\u2500 search_index/   # Search indices\n\u2514\u2500\u2500 metadata/       # File modification times\n</code></pre> <p>The cache automatically rebuilds when files change.</p>"},{"location":"user-guide/configuration/#memory-usage","title":"Memory Usage","text":"<p>For large note collections:</p> <ul> <li>TF-IDF embeddings are memory-efficient</li> <li>Search indices are built incrementally</li> <li>Only modified files are reprocessed</li> </ul>"},{"location":"user-guide/configuration/#security-settings","title":"Security Settings","text":""},{"location":"user-guide/configuration/#api-key-management","title":"API Key Management","text":"<p>Best practices for API key security:</p> <pre><code># Use a secure credential manager\nexport OPENAI_API_KEY=$(security find-generic-password -s openai -w)\n\n# Or use a .env file (not committed to git)\necho \"OPENAI_API_KEY=your-key\" &gt; .env\nsource .env\n</code></pre>"},{"location":"user-guide/configuration/#directory-sandboxing","title":"Directory Sandboxing","text":"<p>Obsidian-AI restricts file access to your brain directory:</p> <ul> <li>Prevents reading files outside the configured directory</li> <li>Blocks directory traversal attacks</li> <li>All file paths are validated and resolved safely</li> </ul>"},{"location":"user-guide/configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"user-guide/configuration/#custom-prompts","title":"Custom Prompts","text":"<p>While not exposed via environment variables, you can modify prompts by:</p> <ol> <li>Forking the repository</li> <li>Editing files in <code>src/obsidian_ai/prompts/</code></li> <li>Installing your custom version</li> </ol>"},{"location":"user-guide/configuration/#integration-scripts","title":"Integration Scripts","text":"<p>Create wrapper scripts for common workflows:</p> <pre><code>#!/bin/bash\n# ai-daily.sh - Find today's notes and related content\n\nDATE=$(date +%Y-%m-%d)\nobsidian-ai chat \"Show me notes from $DATE and anything related to today's work\"\n</code></pre> <pre><code>#!/bin/bash\n# ai-project.sh - Project-specific queries\n\nPROJECT=${1:-\"default\"}\nobsidian-ai --ignore \"personal/*\" chat \"What do I know about project $PROJECT?\"\n</code></pre>"},{"location":"user-guide/configuration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"user-guide/configuration/#research-setup","title":"Research Setup","text":"<p>For academic or research notes:</p> <pre><code>export OBSIDIAN_AI_BRAIN_DIR=\"$HOME/Research\"\nexport OBSIDIAN_AI_MODEL=\"gpt-4o\"\nexport OBSIDIAN_AI_IGNORE_PATTERNS=\"drafts/*,archive/*,*.bib\"\n</code></pre>"},{"location":"user-guide/configuration/#personal-knowledge-base","title":"Personal Knowledge Base","text":"<p>For personal notes and journals:</p> <pre><code>export OBSIDIAN_AI_BRAIN_DIR=\"$HOME/Documents/Notes\"\nexport OBSIDIAN_AI_MODEL=\"gpt-3.5-turbo\"\nexport OBSIDIAN_AI_IGNORE_PATTERNS=\"private/*,diary/*\"\n</code></pre>"},{"location":"user-guide/configuration/#team-documentation","title":"Team Documentation","text":"<p>For shared team knowledge:</p> <pre><code>export OBSIDIAN_AI_BRAIN_DIR=\"/shared/team-docs\"\nexport OBSIDIAN_AI_MODEL=\"gpt-4\"\nexport OBSIDIAN_AI_IGNORE_PATTERNS=\"wip/*,personal/*\"\n</code></pre>"},{"location":"user-guide/configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"user-guide/configuration/#common-issues","title":"Common Issues","text":"<p>Configuration not applied - Restart your terminal after setting environment variables - Check that variables are exported: <code>echo $OBSIDIAN_AI_BRAIN_DIR</code></p> <p>Files not found - Verify the brain directory path is correct - Check file permissions are readable - Ensure files have supported extensions</p> <p>API errors - Validate your API key format - Check OpenAI account status and credits - Verify the model name is correct</p>"},{"location":"user-guide/configuration/#debugging-configuration","title":"Debugging Configuration","text":"<p>View current configuration:</p> <pre><code># Check environment variables\nenv | grep OBSIDIAN_AI\n\n# Test with verbose output\nobsidian-ai -v search \"test\"\n\n# Verify brain directory contents\nobsidian-ai search \"*\" | head -20\n</code></pre>"},{"location":"user-guide/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Learn common usage patterns</li> <li>Explore the API reference</li> <li>Set up development environment</li> </ul>"},{"location":"user-guide/examples/","title":"Usage Examples","text":"<p>This guide demonstrates common usage patterns and workflows with Obsidian-AI.</p>"},{"location":"user-guide/examples/#basic-operations","title":"Basic Operations","text":""},{"location":"user-guide/examples/#single-queries","title":"Single Queries","text":"<p>Quick one-off questions about your notes:</p> <pre><code># Find notes about a topic\nobsidian-ai chat \"What notes do I have about machine learning?\"\n\n# Get summaries\nobsidian-ai chat \"Summarize my thoughts on project management\"\n\n# Find connections\nobsidian-ai chat \"How do my notes on AI relate to my business ideas?\"\n</code></pre>"},{"location":"user-guide/examples/#search-operations","title":"Search Operations","text":"<p>Direct search without AI interpretation:</p> <pre><code># Keyword search\nobsidian-ai search \"neural networks\"\n\n# Exact phrase search\nobsidian-ai search \"machine learning project\"\n\n# Filename search\nobsidian-ai search \"project\"\n</code></pre>"},{"location":"user-guide/examples/#file-reading","title":"File Reading","text":"<p>Read specific files:</p> <pre><code># Read entire file\nobsidian-ai read \"projects/ai-assistant.md\"\n\n# Read file range (useful for large files)\nobsidian-ai read \"research/paper-notes.md\" --start 0 --max-bytes 1024\n\n# Read with ignore patterns\nobsidian-ai --ignore \"drafts/*\" read \"projects/current.md\"\n</code></pre>"},{"location":"user-guide/examples/#interactive-sessions","title":"Interactive Sessions","text":""},{"location":"user-guide/examples/#repl-mode","title":"REPL Mode","text":"<p>Start an interactive conversation:</p> <pre><code>obsidian-ai repl\n</code></pre> <p>Example session: <pre><code>&gt; What projects am I working on?\nBased on your notes, you're currently working on several projects:\n\n1. **AI Assistant Project** - Building a command-line tool for note analysis\n2. **Research Paper** - Writing about transformer architectures\n3. **Data Pipeline** - Developing automated data processing\n\n&gt; Tell me more about the AI Assistant project\nThe AI Assistant project involves creating a tool that can search and analyze\nyour personal knowledge base. Key features include:\n- Semantic search capabilities\n- Wikilink analysis\n- Interactive chat interface\n\n&gt; Who am I collaborating with on these projects?\nFrom your notes, I can see you're collaborating with:\n- John Smith on the AI research\n- Sarah Wilson on data analysis\n- Mike Chen on software development\n\n&gt; exit\n</code></pre></p>"},{"location":"user-guide/examples/#advanced-workflows","title":"Advanced Workflows","text":""},{"location":"user-guide/examples/#research-and-writing","title":"Research and Writing","text":"<p>Find related content while writing:</p> <pre><code># Find background material\nobsidian-ai chat \"What background research do I have on transformers?\"\n\n# Get writing inspiration\nobsidian-ai chat \"What examples of machine learning applications are in my notes?\"\n\n# Check for contradictions\nobsidian-ai chat \"Do I have any conflicting opinions about deep learning approaches?\"\n</code></pre>"},{"location":"user-guide/examples/#project-management","title":"Project Management","text":"<p>Track project status and relationships:</p> <pre><code># Project overview\nobsidian-ai chat \"What's the current status of my AI project?\"\n\n# Team coordination\nobsidian-ai chat \"What tasks have I assigned to team members?\"\n\n# Resource planning\nobsidian-ai chat \"What resources do I need for upcoming projects?\"\n</code></pre>"},{"location":"user-guide/examples/#personal-knowledge-management","title":"Personal Knowledge Management","text":"<p>Discover patterns and connections:</p> <pre><code># Learning progress\nobsidian-ai chat \"What have I learned about Python this month?\"\n\n# Idea development\nobsidian-ai chat \"How have my thoughts on AI ethics evolved?\"\n\n# Memory aids\nobsidian-ai chat \"What did I think about that conference last year?\"\n</code></pre>"},{"location":"user-guide/examples/#specialized-use-cases","title":"Specialized Use Cases","text":""},{"location":"user-guide/examples/#academic-research","title":"Academic Research","text":"<pre><code># Literature review\nobsidian-ai chat \"Summarize the key papers I've read on neural networks\"\n\n# Thesis writing\nobsidian-ai chat \"What evidence do I have to support my hypothesis about...\"\n\n# Citation finding\nobsidian-ai chat \"Which papers discuss transformer attention mechanisms?\"\n</code></pre>"},{"location":"user-guide/examples/#business-planning","title":"Business Planning","text":"<pre><code># Market analysis\nobsidian-ai chat \"What market research have I collected on AI tools?\"\n\n# Competitive analysis\nobsidian-ai chat \"How do competitors compare in my analysis?\"\n\n# Strategy development\nobsidian-ai chat \"What strategic options have I considered?\"\n</code></pre>"},{"location":"user-guide/examples/#creative-writing","title":"Creative Writing","text":"<pre><code># Character development\nobsidian-ai chat \"What characters have I created for my story?\"\n\n# Plot consistency\nobsidian-ai chat \"Are there any plot holes in my story outline?\"\n\n# World building\nobsidian-ai chat \"What details have I established about my fictional world?\"\n</code></pre>"},{"location":"user-guide/examples/#command-line-patterns","title":"Command-Line Patterns","text":""},{"location":"user-guide/examples/#batch-operations","title":"Batch Operations","text":"<p>Process multiple queries:</p> <pre><code># Create a script for daily review\n#!/bin/bash\necho \"=== Today's Tasks ===\"\nobsidian-ai chat \"What tasks do I have for today?\"\n\necho \"=== Recent Progress ===\"\nobsidian-ai chat \"What progress have I made this week?\"\n\necho \"=== Upcoming Deadlines ===\"\nobsidian-ai chat \"What deadlines are coming up?\"\n</code></pre>"},{"location":"user-guide/examples/#filtered-searches","title":"Filtered Searches","text":"<p>Use ignore patterns for focused results:</p> <pre><code># Work-only search\nobsidian-ai --ignore \"personal/*\" --ignore \"diary/*\" chat \"What work projects need attention?\"\n\n# Recent notes only\nobsidian-ai --ignore \"archive/*\" --ignore \"old/*\" search \"machine learning\"\n\n# Exclude drafts\nobsidian-ai --ignore \"*.draft\" --ignore \"wip/*\" chat \"What completed research do I have?\"\n</code></pre>"},{"location":"user-guide/examples/#integration-with-other-tools","title":"Integration with Other Tools","text":"<p>Pipe results to other commands:</p> <pre><code># Save search results\nobsidian-ai search \"project ideas\" &gt; ideas.txt\n\n# Count results\nobsidian-ai search \"meeting\" | wc -l\n\n# Format for other tools\nobsidian-ai chat \"List my project names\" | grep \"^-\" | sort\n</code></pre>"},{"location":"user-guide/examples/#output-formatting","title":"Output Formatting","text":""},{"location":"user-guide/examples/#verbose-output","title":"Verbose Output","text":"<p>Get detailed information about operations:</p> <pre><code># See search process\nobsidian-ai -v search \"machine learning\"\n\n# Debug mode\nobsidian-ai -vv chat \"What's in my notes?\"\n</code></pre>"},{"location":"user-guide/examples/#json-output","title":"JSON Output","text":"<p>For programmatic processing:</p> <pre><code># Get structured search results\nobsidian-ai search --format json \"neural networks\"\n\n# Parse with jq\nobsidian-ai search --format json \"AI\" | jq '.results[].path'\n</code></pre>"},{"location":"user-guide/examples/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/examples/#large-note-collections","title":"Large Note Collections","text":"<p>For collections with thousands of files:</p> <pre><code># Use specific ignore patterns\nexport OBSIDIAN_AI_IGNORE_PATTERNS=\"archive/*,old/*,*.tmp\"\n\n# Focus searches\nobsidian-ai --ignore \"archive/*\" search \"recent project\"\n\n# Use semantic search for better relevance\nobsidian-ai chat \"Find the most relevant notes about machine learning\"\n</code></pre>"},{"location":"user-guide/examples/#memory-management","title":"Memory Management","text":"<p>For systems with limited memory:</p> <pre><code># Process in smaller batches\nobsidian-ai --ignore \"large-files/*\" search \"topic\"\n\n# Clear cache if needed\nrm -rf ~/.obsidian_ai_cache\n\n# Use lighter models\nexport OBSIDIAN_AI_MODEL=\"gpt-3.5-turbo\"\n</code></pre>"},{"location":"user-guide/examples/#error-handling","title":"Error Handling","text":""},{"location":"user-guide/examples/#common-scenarios","title":"Common Scenarios","text":"<p>Handle missing files gracefully:</p> <pre><code># Check if file exists before reading\nif obsidian-ai search \"filename.md\" | grep -q \"filename.md\"; then\n    obsidian-ai read \"filename.md\"\nelse\n    echo \"File not found\"\nfi\n</code></pre>"},{"location":"user-guide/examples/#debugging","title":"Debugging","text":"<p>Troubleshoot issues:</p> <pre><code># Check configuration\nobsidian-ai chat \"test\" -v\n\n# Verify brain directory\nls -la \"$OBSIDIAN_AI_BRAIN_DIR\"\n\n# Test API connection\nobsidian-ai chat \"hello\"\n</code></pre>"},{"location":"user-guide/examples/#automation-examples","title":"Automation Examples","text":""},{"location":"user-guide/examples/#daily-workflows","title":"Daily Workflows","text":"<pre><code>#!/bin/bash\n# daily-review.sh\nDATE=$(date +%Y-%m-%d)\n\necho \"=== Daily Review for $DATE ===\"\nobsidian-ai chat \"What did I work on yesterday?\"\nobsidian-ai chat \"What are my priorities for today?\"\nobsidian-ai chat \"Any upcoming deadlines I should know about?\"\n</code></pre>"},{"location":"user-guide/examples/#weekly-reports","title":"Weekly Reports","text":"<pre><code>#!/bin/bash\n# weekly-summary.sh\nWEEK=$(date +%Y-W%U)\n\necho \"=== Weekly Summary $WEEK ===\"\nobsidian-ai chat \"What did I accomplish this week?\"\nobsidian-ai chat \"What challenges did I encounter?\"\nobsidian-ai chat \"What should I focus on next week?\"\n</code></pre>"},{"location":"user-guide/examples/#project-status","title":"Project Status","text":"<pre><code>#!/bin/bash\n# project-status.sh\nPROJECT=$1\n\nif [ -z \"$PROJECT\" ]; then\n    echo \"Usage: $0 &lt;project-name&gt;\"\n    exit 1\nfi\n\necho \"=== Status for $PROJECT ===\"\nobsidian-ai chat \"What's the current status of $PROJECT?\"\nobsidian-ai chat \"What are the next steps for $PROJECT?\"\nobsidian-ai chat \"Any blockers or risks for $PROJECT?\"\n</code></pre>"},{"location":"user-guide/examples/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/examples/#effective-queries","title":"Effective Queries","text":"<p>Write clear, specific questions:</p> <pre><code># Good: Specific and actionable\nobsidian-ai chat \"What Python libraries have I evaluated for data analysis?\"\n\n# Better: Include context\nobsidian-ai chat \"For my current data science project, what Python libraries have I researched and what are their pros and cons?\"\n\n# Best: Multiple related questions\nobsidian-ai repl\n&gt; What Python libraries have I researched for data analysis?\n&gt; Which ones did I decide to use and why?\n&gt; What issues did I encounter with these libraries?\n</code></pre>"},{"location":"user-guide/examples/#organizing-results","title":"Organizing Results","text":"<p>Structure your workflow:</p> <ol> <li>Explore with broad questions</li> <li>Focus with specific queries  </li> <li>Verify by reading source files</li> <li>Document insights in new notes</li> </ol>"},{"location":"user-guide/examples/#maintaining-context","title":"Maintaining Context","text":"<p>Use REPL mode for related questions:</p> <pre><code>obsidian-ai repl\n&gt; Tell me about my AI project\n&gt; Who are the team members?\n&gt; What's our current progress?\n&gt; What are the main challenges?\n&gt; exit\n</code></pre> <p>This maintains context across the conversation, leading to more coherent and useful responses.</p>"},{"location":"user-guide/examples/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about the API reference</li> <li>Explore development setup</li> <li>Check the architecture guide</li> </ul>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>This guide covers different ways to install and set up Obsidian-AI.</p>"},{"location":"user-guide/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12 or higher</li> <li>OpenAI API key</li> <li>A directory containing your notes (markdown, text, etc.)</li> </ul>"},{"location":"user-guide/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"user-guide/installation/#option-1-install-from-pypi-recommended","title":"Option 1: Install from PyPI (Recommended)","text":"<pre><code>pip install obsidian-ai\n</code></pre>"},{"location":"user-guide/installation/#option-2-install-from-source","title":"Option 2: Install from Source","text":"<p>For development or to get the latest features:</p> <pre><code># Clone the repository\ngit clone https://github.com/sumukshashidhar/obsidian-ai.git\ncd obsidian-ai\n\n# Install with uv (recommended)\nuv sync\nsource .venv/bin/activate\n\n# Or install with pip\npip install -e .\n</code></pre>"},{"location":"user-guide/installation/#option-3-using-pipx-isolated-installation","title":"Option 3: Using pipx (Isolated Installation)","text":"<pre><code>pipx install obsidian-ai\n</code></pre>"},{"location":"user-guide/installation/#environment-setup","title":"Environment Setup","text":""},{"location":"user-guide/installation/#required-configuration","title":"Required Configuration","text":"<p>Set your OpenAI API key:</p> <pre><code>export OPENAI_API_KEY=\"your-api-key-here\"\n</code></pre> <p>API Key Security</p> <p>Never commit your API key to version control. Use environment variables or a secure credential manager.</p>"},{"location":"user-guide/installation/#optional-configuration","title":"Optional Configuration","text":"<p>Configure your brain directory (defaults to <code>~/brain</code>):</p> <pre><code>export OBSIDIAN_AI_BRAIN_DIR=\"$HOME/Documents/MyNotes\"\n</code></pre> <p>Choose your preferred OpenAI model:</p> <pre><code>export OBSIDIAN_AI_MODEL=\"gpt-4o\"  # or gpt-3.5-turbo, gpt-4, etc.\n</code></pre> <p>Set ignore patterns for files you want to exclude:</p> <pre><code>export OBSIDIAN_AI_IGNORE_PATTERNS=\"*.tmp,cache/*,private/*\"\n</code></pre>"},{"location":"user-guide/installation/#verification","title":"Verification","text":"<p>Test your installation:</p> <pre><code># Check version\nobsidian-ai --version\n\n# Test basic functionality\nobsidian-ai search \"test\"\n</code></pre>"},{"location":"user-guide/installation/#shell-integration","title":"Shell Integration","text":""},{"location":"user-guide/installation/#bashzsh","title":"Bash/Zsh","text":"<p>Add to your <code>.bashrc</code> or <code>.zshrc</code>:</p> <pre><code># Obsidian-AI configuration\nexport OPENAI_API_KEY=\"your-api-key\"\nexport OBSIDIAN_AI_BRAIN_DIR=\"$HOME/brain\"\n\n# Convenient aliases\nalias ai-chat=\"obsidian-ai chat\"\nalias ai-search=\"obsidian-ai search\"\nalias ai-repl=\"obsidian-ai repl\"\n</code></pre>"},{"location":"user-guide/installation/#fish-shell","title":"Fish Shell","text":"<p>Add to your <code>config.fish</code>:</p> <pre><code># Obsidian-AI configuration\nset -x OPENAI_API_KEY \"your-api-key\"\nset -x OBSIDIAN_AI_BRAIN_DIR \"$HOME/brain\"\n\n# Convenient aliases\nalias ai-chat=\"obsidian-ai chat\"\nalias ai-search=\"obsidian-ai search\"\nalias ai-repl=\"obsidian-ai repl\"\n</code></pre>"},{"location":"user-guide/installation/#docker-installation","title":"Docker Installation","text":"<p>Run Obsidian-AI in a container:</p> <pre><code>FROM python:3.12-slim\n\nWORKDIR /app\nCOPY . .\nRUN pip install obsidian-ai\n\n# Mount your brain directory\nVOLUME [\"/brain\"]\n\nENV OBSIDIAN_AI_BRAIN_DIR=\"/brain\"\nENTRYPOINT [\"obsidian-ai\"]\n</code></pre> <pre><code># Build and run\ndocker build -t obsidian-ai .\ndocker run -it \\\n  -e OPENAI_API_KEY=\"your-key\" \\\n  -v \"$HOME/brain:/brain\" \\\n  obsidian-ai chat \"What notes do I have?\"\n</code></pre>"},{"location":"user-guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/installation/#common-issues","title":"Common Issues","text":"<p>ImportError: No module named 'obsidian_ai' - Ensure you're using the correct Python environment - Try reinstalling: <code>pip uninstall obsidian-ai &amp;&amp; pip install obsidian-ai</code></p> <p>OpenAI API Error - Verify your API key is set correctly - Check your OpenAI account has sufficient credits - Ensure the model you specified is available</p> <p>Permission Denied - Check that the brain directory exists and is readable - Verify file permissions on your notes directory</p> <p>No Files Found - Ensure your brain directory contains supported file types (.md, .txt, .org, .rst) - Check that files aren't being excluded by ignore patterns</p>"},{"location":"user-guide/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the configuration guide</li> <li>Review common usage patterns</li> <li>Search existing GitHub issues</li> <li>Create a new issue with details about your setup</li> </ol>"},{"location":"user-guide/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Configure Obsidian-AI for your workflow</li> <li>Explore usage examples</li> <li>Learn about advanced features</li> </ul>"},{"location":"user-guide/usage/","title":"Usage Guide","text":"<p>This guide covers the basic usage of Obsidian-AI.</p>"},{"location":"user-guide/usage/#command-line-interface","title":"Command Line Interface","text":""},{"location":"user-guide/usage/#basic-search","title":"Basic Search","text":"<p>Search your knowledge base using semantic search:</p> <pre><code>obsidian-ai search \"machine learning algorithms\"\n</code></pre>"},{"location":"user-guide/usage/#interactive-chat","title":"Interactive Chat","text":"<p>Start an interactive chat session:</p> <pre><code>obsidian-ai chat\n</code></pre>"},{"location":"user-guide/usage/#research-mode","title":"Research Mode","text":"<p>Generate research reports on specific topics:</p> <pre><code>obsidian-ai research \"deep learning trends\"\n</code></pre>"},{"location":"user-guide/usage/#python-api","title":"Python API","text":""},{"location":"user-guide/usage/#basic-usage","title":"Basic Usage","text":"<pre><code>from obsidian_ai import search_engine, embedding_service\n\n# Search your knowledge base\nresults = search_engine.search(\"neural networks\", max_results=5)\n\n# Semantic search\nsemantic_results = embedding_service.semantic_search(\"AI research\", k=10)\n</code></pre>"},{"location":"user-guide/usage/#configuration","title":"Configuration","text":"<pre><code>from obsidian_ai.infrastructure.config import config\n\n# Access configuration\nprint(f\"Brain directory: {config.brain_dir}\")\nprint(f\"Model: {config.model}\")\n</code></pre>"},{"location":"user-guide/usage/#features","title":"Features","text":""},{"location":"user-guide/usage/#wikilink-support","title":"WikiLink Support","text":"<p>Obsidian-AI fully supports WikiLinks in your markdown files:</p> <ul> <li><code>[[Simple Link]]</code></li> <li><code>[[Link|Display Text]]</code></li> <li><code>[[Link with [nested] brackets]]</code></li> </ul>"},{"location":"user-guide/usage/#file-system-integration","title":"File System Integration","text":"<ul> <li>Automatic file discovery</li> <li>Respect for .gitignore patterns</li> <li>Safe file operations with security checks</li> </ul>"},{"location":"user-guide/usage/#ai-powered-features","title":"AI-Powered Features","text":"<ul> <li>Semantic search using local embeddings</li> <li>Context-aware responses</li> <li>Research report generation</li> <li>Multi-step reasoning</li> </ul>"},{"location":"user-guide/usage/#best-practices","title":"Best Practices","text":"<ol> <li>Organization: Keep your notes well-organized with clear titles</li> <li>Linking: Use WikiLinks to connect related concepts</li> <li>Tagging: Use consistent tagging for better search results</li> <li>Regular Updates: Keep your knowledge base current</li> </ol>"},{"location":"user-guide/usage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/usage/#common-issues","title":"Common Issues","text":"<p>Q: Search returns no results A: Check that your brain directory is correctly configured and contains markdown files.</p> <p>Q: OpenAI API errors A: Ensure your <code>OPENAI_API_KEY</code> environment variable is set.</p> <p>Q: Slow performance A: Consider adjusting the <code>max_tool_calls</code> configuration parameter.</p> <p>For more help, see our troubleshooting guide or contribute to the project.</p>"}]}